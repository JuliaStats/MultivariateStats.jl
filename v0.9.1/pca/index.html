<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Principal Component Analysis · MultivariateStats.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MultivariateStats.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../whiten/">Data Transformation</a></li><li><a class="tocitem" href="../lreg/">Regression</a></li><li><a class="tocitem" href="../lda/">Linear Discriminant Analysis</a></li><li class="is-active"><a class="tocitem" href>Principal Component Analysis</a><ul class="internal"><li><a class="tocitem" href="#Example"><span>Example</span></a></li><li><a class="tocitem" href="#Linear-Principal-Component-Analysis"><span>Linear Principal Component Analysis</span></a></li><li><a class="tocitem" href="#Kernel-Principal-Component-Analysis"><span>Kernel Principal Component Analysis</span></a></li><li><a class="tocitem" href="#Probabilistic-Principal-Component-Analysis"><span>Probabilistic Principal Component Analysis</span></a></li></ul></li><li><a class="tocitem" href="../ica/">Independent Component Analysis</a></li><li><a class="tocitem" href="../cca/">Canonical Correlation Analysis</a></li><li><a class="tocitem" href="../fa/">Factor Analysis</a></li><li><a class="tocitem" href="../mds/">Multidimensional Scaling</a></li><li><a class="tocitem" href="../api/">Development</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Principal Component Analysis</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Principal Component Analysis</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/master/docs/src/pca.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Principal-Component-Analysis"><a class="docs-heading-anchor" href="#Principal-Component-Analysis">Principal Component Analysis</a><a id="Principal-Component-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Principal-Component-Analysis" title="Permalink"></a></h1><p><a href="http://en.wikipedia.org/wiki/Principal_component_analysis">Principal Component Analysis</a> (PCA) derives an orthogonal projection to convert a given set of observations to linearly uncorrelated variables, called <em>principal components</em>.</p><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><p>Performing <a href="#MultivariateStats.PCA"><code>PCA</code></a> on <em>Iris</em> data set:</p><pre><code class="language-julia hljs">using MultivariateStats, RDatasets, Plots

# load iris dataset
iris = dataset(&quot;datasets&quot;, &quot;iris&quot;)

# split half to training set
Xtr = Matrix(iris[1:2:end,1:4])&#39;
Xtr_labels = Vector(iris[1:2:end,5])

# split other half to testing set
Xte = Matrix(iris[2:2:end,1:4])&#39;
Xte_labels = Vector(iris[2:2:end,5])</code></pre><p>Suppose <code>Xtr</code> and <code>Xte</code> are training and testing data matrix, with each observation in a column. We train a PCA model, allowing up to 3 dimensions:</p><pre><code class="language-julia hljs">M = fit(PCA, Xtr; maxoutdim=3)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PCA(indim = 4, outdim = 3, principalratio = 0.9957325846529409)

Pattern matrix (unstandardized loadings):
────────────────────────────────────
         PC1         PC2         PC3
────────────────────────────────────
1   0.70954    0.344711   -0.160106
2  -0.227592   0.29865     0.215417
3   1.77976   -0.0797511   0.0197705
4   0.764206  -0.0453779   0.166764
────────────────────────────────────

Importance of components:
─────────────────────────────────────────────────────────
                                PC1        PC2        PC3
─────────────────────────────────────────────────────────
SS Loadings (Eigenvalues)  4.3068    0.216437   0.100239
Variance explained         0.927532  0.0466128  0.021588
Cumulative variance        0.927532  0.974145   0.995733
Proportion explained       0.931507  0.0468125  0.0216805
Cumulative proportion      0.931507  0.978319   1.0
─────────────────────────────────────────────────────────</code></pre><p>Then, apply PCA model to the testing set</p><pre><code class="language-julia hljs">Yte = predict(M, Xte)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×75 Matrix{Float64}:
  2.72714    2.75491     2.32396   …  -1.92047   -1.74161   -1.37706
 -0.230916  -0.406149    0.646374      0.246554   0.127625  -0.280295
  0.253119   0.0271266  -0.230469     -0.180044  -0.123165  -0.314992</code></pre><p>And, reconstruct testing observations (approximately) to the original space</p><pre><code class="language-julia hljs">Xr = reconstruct(M, Yte)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×75 Matrix{Float64}:
 4.86449  4.61087   5.40782   5.00775   …  6.79346  6.58825  6.46774  5.94384
 3.04262  3.08695   3.89061   3.39069      3.20785  3.13416  3.03873  2.94737
 1.46099  1.48132   1.68656   1.48668      5.91124  5.39197  5.25542  5.02469
 0.10362  0.229519  0.421233  0.221041     2.28224  1.99665  1.91243  1.91901</code></pre><p>Now, we group results by testing set labels for color coding and visualize first 3 principal components in 3D plot</p><pre><code class="language-julia hljs">setosa = Yte[:,Xte_labels.==&quot;setosa&quot;]
versicolor = Yte[:,Xte_labels.==&quot;versicolor&quot;]
virginica = Yte[:,Xte_labels.==&quot;virginica&quot;]

p = scatter(setosa[1,:],setosa[2,:],setosa[3,:],marker=:circle,linewidth=0)
scatter!(versicolor[1,:],versicolor[2,:],versicolor[3,:],marker=:circle,linewidth=0)
scatter!(virginica[1,:],virginica[2,:],virginica[3,:],marker=:circle,linewidth=0)
plot!(p,xlabel=&quot;PC1&quot;,ylabel=&quot;PC2&quot;,zlabel=&quot;PC3&quot;)</code></pre><?xml version="1.0" encoding="utf-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600">
<defs>
  <clipPath id="clip600">
    <rect x="0" y="0" width="2400" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip600)" d="
M0 1600 L2400 1600 L2400 0 L0 0  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip601">
    <rect x="480" y="0" width="1681" height="1600"/>
  </clipPath>
</defs>
<defs>
  <clipPath id="clip602">
    <rect x="287" y="47" width="2066" height="1377"/>
  </clipPath>
</defs>
<path clip-path="url(#clip602)" d="
M287.366 1341.9 L287.366 291.086 L1043.35 47.2441 L2352.76 128.525 L2352.76 1179.34 L1596.77 1423.18 L287.366 1341.9  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  403.217,1349.09 1159.2,1105.25 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1159.2,1105.25 1159.2,54.4355 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  588.958,1360.62 1344.94,1116.78 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1344.94,1116.78 1344.94,65.9653 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  774.699,1372.15 1530.68,1128.31 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1530.68,1128.31 1530.68,77.4951 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  960.44,1383.68 1716.43,1139.84 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1716.43,1139.84 1716.43,89.0249 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1146.18,1395.21 1902.17,1151.37 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1902.17,1151.37 1902.17,100.555 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1331.92,1406.74 2087.91,1162.9 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2087.91,1162.9 2087.91,112.084 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1517.66,1418.27 2273.65,1174.43 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2273.65,1174.43 2273.65,123.614 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  287.366,1341.9 1596.77,1423.18 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  403.217,1349.09 412.289,1346.16 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  588.958,1360.62 598.03,1357.69 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  774.699,1372.15 783.771,1369.22 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  960.44,1383.68 969.512,1380.75 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1146.18,1395.21 1155.25,1392.28 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1331.92,1406.74 1340.99,1403.81 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1517.66,1418.27 1526.74,1415.34 
  "/>
<path clip-path="url(#clip600)" d="M340.368 1378.29 L370.044 1378.29 L370.044 1382.22 L340.368 1382.22 L340.368 1378.29 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M394.303 1376.48 Q397.659 1377.2 399.534 1379.47 Q401.432 1381.74 401.432 1385.07 Q401.432 1390.18 397.914 1392.99 Q394.395 1395.79 387.914 1395.79 Q385.738 1395.79 383.423 1395.35 Q381.132 1394.93 378.678 1394.07 L378.678 1389.56 Q380.622 1390.69 382.937 1391.27 Q385.252 1391.85 387.775 1391.85 Q392.173 1391.85 394.465 1390.12 Q396.78 1388.38 396.78 1385.07 Q396.78 1382.01 394.627 1380.3 Q392.497 1378.56 388.678 1378.56 L384.65 1378.56 L384.65 1374.72 L388.863 1374.72 Q392.312 1374.72 394.141 1373.36 Q395.97 1371.97 395.97 1369.37 Q395.97 1366.71 394.071 1365.3 Q392.196 1363.87 388.678 1363.87 Q386.757 1363.87 384.558 1364.28 Q382.358 1364.7 379.72 1365.58 L379.72 1361.41 Q382.382 1360.67 384.696 1360.3 Q387.034 1359.93 389.095 1359.93 Q394.419 1359.93 397.52 1362.36 Q400.622 1364.77 400.622 1368.89 Q400.622 1371.76 398.979 1373.75 Q397.335 1375.72 394.303 1376.48 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M527.058 1389.82 L556.734 1389.82 L556.734 1393.75 L527.058 1393.75 L527.058 1389.82 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M570.854 1402.71 L587.174 1402.71 L587.174 1406.65 L565.229 1406.65 L565.229 1402.71 Q567.891 1399.96 572.475 1395.33 Q577.081 1390.67 578.262 1389.33 Q580.507 1386.81 581.387 1385.07 Q582.289 1383.31 582.289 1381.62 Q582.289 1378.87 580.345 1377.13 Q578.424 1375.4 575.322 1375.4 Q573.123 1375.4 570.669 1376.16 Q568.239 1376.92 565.461 1378.47 L565.461 1373.75 Q568.285 1372.62 570.739 1372.04 Q573.192 1371.46 575.229 1371.46 Q580.6 1371.46 583.794 1374.15 Q586.988 1376.83 586.988 1381.32 Q586.988 1383.45 586.178 1385.37 Q585.391 1387.27 583.285 1389.86 Q582.706 1390.53 579.604 1393.75 Q576.502 1396.95 570.854 1402.71 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M712.429 1401.35 L742.105 1401.35 L742.105 1405.28 L712.429 1405.28 L712.429 1401.35 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M753.008 1414.24 L760.646 1414.24 L760.646 1387.87 L752.336 1389.54 L752.336 1385.28 L760.6 1383.61 L765.276 1383.61 L765.276 1414.24 L772.915 1414.24 L772.915 1418.17 L753.008 1418.17 L753.008 1414.24 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M946.712 1398.22 Q943.101 1398.22 941.272 1401.79 Q939.466 1405.33 939.466 1412.46 Q939.466 1419.57 941.272 1423.13 Q943.101 1426.67 946.712 1426.67 Q950.346 1426.67 952.151 1423.13 Q953.98 1419.57 953.98 1412.46 Q953.98 1405.33 952.151 1401.79 Q950.346 1398.22 946.712 1398.22 M946.712 1394.52 Q952.522 1394.52 955.577 1399.13 Q958.656 1403.71 958.656 1412.46 Q958.656 1421.19 955.577 1425.79 Q952.522 1430.38 946.712 1430.38 Q940.901 1430.38 937.823 1425.79 Q934.767 1421.19 934.767 1412.46 Q934.767 1403.71 937.823 1399.13 Q940.901 1394.52 946.712 1394.52 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1124.49 1437.3 L1132.13 1437.3 L1132.13 1410.93 L1123.82 1412.6 L1123.82 1408.34 L1132.08 1406.67 L1136.76 1406.67 L1136.76 1437.3 L1144.4 1437.3 L1144.4 1441.23 L1124.49 1441.23 L1124.49 1437.3 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1313.82 1448.83 L1330.14 1448.83 L1330.14 1452.76 L1308.19 1452.76 L1308.19 1448.83 Q1310.86 1446.07 1315.44 1441.44 Q1320.05 1436.79 1321.23 1435.45 Q1323.47 1432.93 1324.35 1431.19 Q1325.25 1429.43 1325.25 1427.74 Q1325.25 1424.99 1323.31 1423.25 Q1321.39 1421.51 1318.29 1421.51 Q1316.09 1421.51 1313.63 1422.28 Q1311.2 1423.04 1308.43 1424.59 L1308.43 1419.87 Q1311.25 1418.74 1313.7 1418.16 Q1316.16 1417.58 1318.19 1417.58 Q1323.56 1417.58 1326.76 1420.26 Q1329.95 1422.95 1329.95 1427.44 Q1329.95 1429.57 1329.14 1431.49 Q1328.36 1433.39 1326.25 1435.98 Q1325.67 1436.65 1322.57 1439.87 Q1319.47 1443.07 1313.82 1448.83 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1508.75 1445.66 Q1512.11 1446.38 1513.98 1448.65 Q1515.88 1450.91 1515.88 1454.25 Q1515.88 1459.36 1512.36 1462.16 Q1508.84 1464.97 1502.36 1464.97 Q1500.19 1464.97 1497.87 1464.53 Q1495.58 1464.11 1493.12 1463.25 L1493.12 1458.74 Q1495.07 1459.87 1497.38 1460.45 Q1499.7 1461.03 1502.22 1461.03 Q1506.62 1461.03 1508.91 1459.29 Q1511.23 1457.56 1511.23 1454.25 Q1511.23 1451.19 1509.07 1449.48 Q1506.94 1447.74 1503.12 1447.74 L1499.1 1447.74 L1499.1 1443.9 L1503.31 1443.9 Q1506.76 1443.9 1508.59 1442.53 Q1510.42 1441.15 1510.42 1438.55 Q1510.42 1435.89 1508.52 1434.48 Q1506.64 1433.04 1503.12 1433.04 Q1501.2 1433.04 1499 1433.46 Q1496.81 1433.88 1494.17 1434.76 L1494.17 1430.59 Q1496.83 1429.85 1499.14 1429.48 Q1501.48 1429.11 1503.54 1429.11 Q1508.87 1429.11 1511.97 1431.54 Q1515.07 1433.95 1515.07 1438.07 Q1515.07 1440.94 1513.43 1442.93 Q1511.78 1444.9 1508.75 1445.66 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M768.436 1520.45 L768.436 1538.3 L776.521 1538.3 Q781.009 1538.3 783.459 1535.98 Q785.91 1533.66 785.91 1529.36 Q785.91 1525.09 783.459 1522.77 Q781.009 1520.45 776.521 1520.45 L768.436 1520.45 M762.007 1515.16 L776.521 1515.16 Q784.51 1515.16 788.584 1518.79 Q792.69 1522.39 792.69 1529.36 Q792.69 1536.39 788.584 1539.99 Q784.51 1543.59 776.521 1543.59 L768.436 1543.59 L768.436 1562.68 L762.007 1562.68 L762.007 1515.16 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M836.9 1518.82 L836.9 1525.6 Q833.653 1522.58 829.961 1521.08 Q826.301 1519.59 822.163 1519.59 Q814.015 1519.59 809.686 1524.58 Q805.358 1529.55 805.358 1538.97 Q805.358 1548.36 809.686 1553.36 Q814.015 1558.32 822.163 1558.32 Q826.301 1558.32 829.961 1556.83 Q833.653 1555.33 836.9 1552.31 L836.9 1559.02 Q833.526 1561.31 829.738 1562.46 Q825.982 1563.61 821.781 1563.61 Q810.991 1563.61 804.785 1557.02 Q798.578 1550.4 798.578 1538.97 Q798.578 1527.51 804.785 1520.92 Q810.991 1514.3 821.781 1514.3 Q826.046 1514.3 829.802 1515.45 Q833.589 1516.56 836.9 1518.82 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M848.517 1557.27 L859.02 1557.27 L859.02 1521.02 L847.594 1523.31 L847.594 1517.46 L858.957 1515.16 L865.386 1515.16 L865.386 1557.27 L875.89 1557.27 L875.89 1562.68 L848.517 1562.68 L848.517 1557.27 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1623.84,1414.45 314.432,1333.17 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  314.432,1333.17 314.432,282.356 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1766.9,1368.31 457.493,1287.02 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  457.493,1287.02 457.493,236.212 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1909.96,1322.16 600.554,1240.88 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  600.554,1240.88 600.554,190.068 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2053.02,1276.02 743.615,1194.74 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  743.615,1194.74 743.615,143.924 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2196.08,1229.87 886.676,1148.59 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  886.676,1148.59 886.676,97.7794 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2339.14,1183.73 1029.74,1102.45 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1029.74,1102.45 1029.74,51.6353 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1596.77,1423.18 2352.76,1179.34 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1623.84,1414.45 1608.12,1413.47 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1766.9,1368.31 1751.19,1367.33 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1909.96,1322.16 1894.25,1321.19 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  2053.02,1276.02 2037.31,1275.04 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  2196.08,1229.87 2180.37,1228.9 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  2339.14,1183.73 2323.43,1182.75 
  "/>
<path clip-path="url(#clip600)" d="M1632.68 1442.31 L1662.35 1442.31 L1662.35 1446.25 L1632.68 1446.25 L1632.68 1442.31 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1673.26 1455.2 L1680.9 1455.2 L1680.9 1428.84 L1672.59 1430.51 L1672.59 1426.25 L1680.85 1424.58 L1685.52 1424.58 L1685.52 1455.2 L1693.16 1455.2 L1693.16 1459.14 L1673.26 1459.14 L1673.26 1455.2 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1702.61 1453.26 L1707.49 1453.26 L1707.49 1459.14 L1702.61 1459.14 L1702.61 1453.26 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1727.68 1427.66 Q1724.07 1427.66 1722.24 1431.22 Q1720.43 1434.76 1720.43 1441.89 Q1720.43 1449 1722.24 1452.57 Q1724.07 1456.11 1727.68 1456.11 Q1731.31 1456.11 1733.12 1452.57 Q1734.95 1449 1734.95 1441.89 Q1734.95 1434.76 1733.12 1431.22 Q1731.31 1427.66 1727.68 1427.66 M1727.68 1423.95 Q1733.49 1423.95 1736.54 1428.56 Q1739.62 1433.14 1739.62 1441.89 Q1739.62 1450.62 1736.54 1455.23 Q1733.49 1459.81 1727.68 1459.81 Q1721.87 1459.81 1718.79 1455.23 Q1715.73 1450.62 1715.73 1441.89 Q1715.73 1433.14 1718.79 1428.56 Q1721.87 1423.95 1727.68 1423.95 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1775.74 1396.17 L1805.41 1396.17 L1805.41 1400.1 L1775.74 1400.1 L1775.74 1396.17 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1825.51 1381.51 Q1821.9 1381.51 1820.07 1385.08 Q1818.26 1388.62 1818.26 1395.75 Q1818.26 1402.86 1820.07 1406.42 Q1821.9 1409.96 1825.51 1409.96 Q1829.14 1409.96 1830.95 1406.42 Q1832.78 1402.86 1832.78 1395.75 Q1832.78 1388.62 1830.95 1385.08 Q1829.14 1381.51 1825.51 1381.51 M1825.51 1377.81 Q1831.32 1377.81 1834.37 1382.42 Q1837.45 1387 1837.45 1395.75 Q1837.45 1404.48 1834.37 1409.08 Q1831.32 1413.67 1825.51 1413.67 Q1819.7 1413.67 1816.62 1409.08 Q1813.56 1404.48 1813.56 1395.75 Q1813.56 1387 1816.62 1382.42 Q1819.7 1377.81 1825.51 1377.81 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1845.67 1407.12 L1850.55 1407.12 L1850.55 1413 L1845.67 1413 L1845.67 1407.12 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1860.78 1378.44 L1879.14 1378.44 L1879.14 1382.37 L1865.07 1382.37 L1865.07 1390.84 Q1866.09 1390.5 1867.1 1390.33 Q1868.12 1390.15 1869.14 1390.15 Q1874.93 1390.15 1878.31 1393.32 Q1881.69 1396.49 1881.69 1401.91 Q1881.69 1407.49 1878.22 1410.59 Q1874.74 1413.67 1868.42 1413.67 Q1866.25 1413.67 1863.98 1413.3 Q1861.73 1412.93 1859.33 1412.18 L1859.33 1407.49 Q1861.41 1408.62 1863.63 1409.18 Q1865.85 1409.73 1868.33 1409.73 Q1872.34 1409.73 1874.67 1407.62 Q1877.01 1405.52 1877.01 1401.91 Q1877.01 1398.3 1874.67 1396.19 Q1872.34 1394.08 1868.33 1394.08 Q1866.46 1394.08 1864.58 1394.5 Q1862.73 1394.92 1860.78 1395.8 L1860.78 1378.44 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1930.74 1335.37 Q1927.13 1335.37 1925.3 1338.93 Q1923.5 1342.48 1923.5 1349.61 Q1923.5 1356.71 1925.3 1360.28 Q1927.13 1363.82 1930.74 1363.82 Q1934.38 1363.82 1936.18 1360.28 Q1938.01 1356.71 1938.01 1349.61 Q1938.01 1342.48 1936.18 1338.93 Q1934.38 1335.37 1930.74 1335.37 M1930.74 1331.67 Q1936.55 1331.67 1939.61 1336.27 Q1942.69 1340.86 1942.69 1349.61 Q1942.69 1358.33 1939.61 1362.94 Q1936.55 1367.52 1930.74 1367.52 Q1924.93 1367.52 1921.86 1362.94 Q1918.8 1358.33 1918.8 1349.61 Q1918.8 1340.86 1921.86 1336.27 Q1924.93 1331.67 1930.74 1331.67 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1950.91 1360.97 L1955.79 1360.97 L1955.79 1366.85 L1950.91 1366.85 L1950.91 1360.97 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1975.98 1335.37 Q1972.36 1335.37 1970.54 1338.93 Q1968.73 1342.48 1968.73 1349.61 Q1968.73 1356.71 1970.54 1360.28 Q1972.36 1363.82 1975.98 1363.82 Q1979.61 1363.82 1981.42 1360.28 Q1983.24 1356.71 1983.24 1349.61 Q1983.24 1342.48 1981.42 1338.93 Q1979.61 1335.37 1975.98 1335.37 M1975.98 1331.67 Q1981.79 1331.67 1984.84 1336.27 Q1987.92 1340.86 1987.92 1349.61 Q1987.92 1358.33 1984.84 1362.94 Q1981.79 1367.52 1975.98 1367.52 Q1970.17 1367.52 1967.09 1362.94 Q1964.03 1358.33 1964.03 1349.61 Q1964.03 1340.86 1967.09 1336.27 Q1970.17 1331.67 1975.98 1331.67 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2073.81 1289.23 Q2070.19 1289.23 2068.37 1292.79 Q2066.56 1296.33 2066.56 1303.46 Q2066.56 1310.57 2068.37 1314.13 Q2070.19 1317.67 2073.81 1317.67 Q2077.44 1317.67 2079.24 1314.13 Q2081.07 1310.57 2081.07 1303.46 Q2081.07 1296.33 2079.24 1292.79 Q2077.44 1289.23 2073.81 1289.23 M2073.81 1285.52 Q2079.62 1285.52 2082.67 1290.13 Q2085.75 1294.71 2085.75 1303.46 Q2085.75 1312.19 2082.67 1316.79 Q2079.62 1321.38 2073.81 1321.38 Q2067.99 1321.38 2064.92 1316.79 Q2061.86 1312.19 2061.86 1303.46 Q2061.86 1294.71 2064.92 1290.13 Q2067.99 1285.52 2073.81 1285.52 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2093.97 1314.83 L2098.85 1314.83 L2098.85 1320.71 L2093.97 1320.71 L2093.97 1314.83 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2109.08 1286.15 L2127.44 1286.15 L2127.44 1290.08 L2113.37 1290.08 L2113.37 1298.55 Q2114.38 1298.21 2115.4 1298.04 Q2116.42 1297.86 2117.44 1297.86 Q2123.23 1297.86 2126.61 1301.03 Q2129.99 1304.2 2129.99 1309.62 Q2129.99 1315.2 2126.51 1318.3 Q2123.04 1321.38 2116.72 1321.38 Q2114.55 1321.38 2112.28 1321.01 Q2110.03 1320.64 2107.62 1319.9 L2107.62 1315.2 Q2109.71 1316.33 2111.93 1316.89 Q2114.15 1317.44 2116.63 1317.44 Q2120.63 1317.44 2122.97 1315.34 Q2125.31 1313.23 2125.31 1309.62 Q2125.31 1306.01 2122.97 1303.9 Q2120.63 1301.79 2116.63 1301.79 Q2114.75 1301.79 2112.88 1302.21 Q2111.03 1302.63 2109.08 1303.51 L2109.08 1286.15 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2205.59 1270.63 L2213.23 1270.63 L2213.23 1244.26 L2204.92 1245.93 L2204.92 1241.67 L2213.19 1240 L2217.86 1240 L2217.86 1270.63 L2225.5 1270.63 L2225.5 1274.56 L2205.59 1274.56 L2205.59 1270.63 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2234.94 1268.68 L2239.83 1268.68 L2239.83 1274.56 L2234.94 1274.56 L2234.94 1268.68 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2260.01 1243.08 Q2256.4 1243.08 2254.57 1246.65 Q2252.77 1250.19 2252.77 1257.32 Q2252.77 1264.42 2254.57 1267.99 Q2256.4 1271.53 2260.01 1271.53 Q2263.65 1271.53 2265.45 1267.99 Q2267.28 1264.42 2267.28 1257.32 Q2267.28 1250.19 2265.45 1246.65 Q2263.65 1243.08 2260.01 1243.08 M2260.01 1239.38 Q2265.82 1239.38 2268.88 1243.98 Q2271.96 1248.57 2271.96 1257.32 Q2271.96 1266.04 2268.88 1270.65 Q2265.82 1275.23 2260.01 1275.23 Q2254.2 1275.23 2251.13 1270.65 Q2248.07 1266.04 2248.07 1257.32 Q2248.07 1248.57 2251.13 1243.98 Q2254.2 1239.38 2260.01 1239.38 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2348.65 1224.48 L2356.29 1224.48 L2356.29 1198.12 L2347.98 1199.78 L2347.98 1195.53 L2356.25 1193.86 L2360.92 1193.86 L2360.92 1224.48 L2368.56 1224.48 L2368.56 1228.42 L2348.65 1228.42 L2348.65 1224.48 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2378.01 1222.54 L2382.89 1222.54 L2382.89 1228.42 L2378.01 1228.42 L2378.01 1222.54 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2393.12 1193.86 L2411.48 1193.86 L2411.48 1197.79 L2397.4 1197.79 L2397.4 1206.27 Q2398.42 1205.92 2399.44 1205.76 Q2400.46 1205.57 2401.48 1205.57 Q2407.26 1205.57 2410.64 1208.74 Q2414.02 1211.91 2414.02 1217.33 Q2414.02 1222.91 2410.55 1226.01 Q2407.08 1229.09 2400.76 1229.09 Q2398.58 1229.09 2396.32 1228.72 Q2394.07 1228.35 2391.66 1227.61 L2391.66 1222.91 Q2393.75 1224.04 2395.97 1224.6 Q2398.19 1225.15 2400.67 1225.15 Q2404.67 1225.15 2407.01 1223.05 Q2409.35 1220.94 2409.35 1217.33 Q2409.35 1213.72 2407.01 1211.61 Q2404.67 1209.51 2400.67 1209.51 Q2398.79 1209.51 2396.92 1209.92 Q2395.07 1210.34 2393.12 1211.22 L2393.12 1193.86 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2047.63 1439.17 L2047.63 1457.02 L2055.71 1457.02 Q2060.2 1457.02 2062.65 1454.7 Q2065.1 1452.38 2065.1 1448.08 Q2065.1 1443.81 2062.65 1441.49 Q2060.2 1439.17 2055.71 1439.17 L2047.63 1439.17 M2041.2 1433.88 L2055.71 1433.88 Q2063.7 1433.88 2067.77 1437.51 Q2071.88 1441.11 2071.88 1448.08 Q2071.88 1455.11 2067.77 1458.71 Q2063.7 1462.31 2055.71 1462.31 L2047.63 1462.31 L2047.63 1481.4 L2041.2 1481.4 L2041.2 1433.88 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2116.09 1437.54 L2116.09 1444.32 Q2112.84 1441.3 2109.15 1439.8 Q2105.49 1438.31 2101.35 1438.31 Q2093.2 1438.31 2088.88 1443.3 Q2084.55 1448.27 2084.55 1457.69 Q2084.55 1467.08 2088.88 1472.08 Q2093.2 1477.04 2101.35 1477.04 Q2105.49 1477.04 2109.15 1475.55 Q2112.84 1474.05 2116.09 1471.03 L2116.09 1477.74 Q2112.72 1480.03 2108.93 1481.18 Q2105.17 1482.33 2100.97 1482.33 Q2090.18 1482.33 2083.97 1475.74 Q2077.77 1469.12 2077.77 1457.69 Q2077.77 1446.23 2083.97 1439.64 Q2090.18 1433.02 2100.97 1433.02 Q2105.24 1433.02 2108.99 1434.17 Q2112.78 1435.28 2116.09 1437.54 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2132.13 1475.99 L2154.57 1475.99 L2154.57 1481.4 L2124.4 1481.4 L2124.4 1475.99 Q2128.06 1472.2 2134.36 1465.84 Q2140.69 1459.44 2142.32 1457.6 Q2145.4 1454.13 2146.61 1451.74 Q2147.85 1449.32 2147.85 1447 Q2147.85 1443.21 2145.18 1440.82 Q2142.54 1438.43 2138.27 1438.43 Q2135.25 1438.43 2131.88 1439.48 Q2128.53 1440.53 2124.71 1442.67 L2124.71 1436.17 Q2128.6 1434.61 2131.97 1433.82 Q2135.35 1433.02 2138.15 1433.02 Q2145.53 1433.02 2149.92 1436.72 Q2154.32 1440.41 2154.32 1446.58 Q2154.32 1449.51 2153.2 1452.15 Q2152.12 1454.76 2149.22 1458.33 Q2148.43 1459.25 2144.16 1463.67 Q2139.9 1468.07 2132.13 1475.99 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  287.366,1314.72 1043.35,1070.88 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1043.35,1070.88 2352.76,1152.16 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  287.366,1102.47 1043.35,858.626 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1043.35,858.626 2352.76,939.906 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  287.366,890.212 1043.35,646.37 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1043.35,646.37 2352.76,727.65 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  287.366,677.955 1043.35,434.113 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1043.35,434.113 2352.76,515.394 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  287.366,465.699 1043.35,221.857 
  "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1043.35,221.857 2352.76,303.138 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  287.366,1341.9 287.366,291.086 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  287.366,1314.72 296.438,1311.8 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  287.366,1102.47 296.438,1099.54 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  287.366,890.212 296.438,887.285 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  287.366,677.955 296.438,675.029 
  "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  287.366,465.699 296.438,462.773 
  "/>
<path clip-path="url(#clip600)" d="M121.46 1315.18 L151.136 1315.18 L151.136 1319.11 L121.46 1319.11 L121.46 1315.18 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M171.228 1300.52 Q167.617 1300.52 165.789 1304.09 Q163.983 1307.63 163.983 1314.76 Q163.983 1321.86 165.789 1325.43 Q167.617 1328.97 171.228 1328.97 Q174.863 1328.97 176.668 1325.43 Q178.497 1321.86 178.497 1314.76 Q178.497 1307.63 176.668 1304.09 Q174.863 1300.52 171.228 1300.52 M171.228 1296.82 Q177.039 1296.82 180.094 1301.43 Q183.173 1306.01 183.173 1314.76 Q183.173 1323.49 180.094 1328.09 Q177.039 1332.67 171.228 1332.67 Q165.418 1332.67 162.34 1328.09 Q159.284 1323.49 159.284 1314.76 Q159.284 1306.01 162.34 1301.43 Q165.418 1296.82 171.228 1296.82 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M191.39 1326.12 L196.275 1326.12 L196.275 1332 L191.39 1332 L191.39 1326.12 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M206.506 1297.44 L224.862 1297.44 L224.862 1301.38 L210.788 1301.38 L210.788 1309.85 Q211.807 1309.5 212.825 1309.34 Q213.844 1309.16 214.862 1309.16 Q220.649 1309.16 224.029 1312.33 Q227.409 1315.5 227.409 1320.92 Q227.409 1326.49 223.936 1329.6 Q220.464 1332.67 214.145 1332.67 Q211.969 1332.67 209.7 1332.3 Q207.455 1331.93 205.048 1331.19 L205.048 1326.49 Q207.131 1327.63 209.353 1328.18 Q211.575 1328.74 214.052 1328.74 Q218.057 1328.74 220.395 1326.63 Q222.733 1324.53 222.733 1320.92 Q222.733 1317.3 220.395 1315.2 Q218.057 1313.09 214.052 1313.09 Q212.177 1313.09 210.302 1313.51 Q208.45 1313.93 206.506 1314.8 L206.506 1297.44 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M246.622 1300.52 Q243.01 1300.52 241.182 1304.09 Q239.376 1307.63 239.376 1314.76 Q239.376 1321.86 241.182 1325.43 Q243.01 1328.97 246.622 1328.97 Q250.256 1328.97 252.061 1325.43 Q253.89 1321.86 253.89 1314.76 Q253.89 1307.63 252.061 1304.09 Q250.256 1300.52 246.622 1300.52 M246.622 1296.82 Q252.432 1296.82 255.487 1301.43 Q258.566 1306.01 258.566 1314.76 Q258.566 1323.49 255.487 1328.09 Q252.432 1332.67 246.622 1332.67 Q240.811 1332.67 237.733 1328.09 Q234.677 1323.49 234.677 1314.76 Q234.677 1306.01 237.733 1301.43 Q240.811 1296.82 246.622 1296.82 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M122.456 1102.92 L152.131 1102.92 L152.131 1106.85 L122.456 1106.85 L122.456 1102.92 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M172.224 1088.27 Q168.613 1088.27 166.784 1091.83 Q164.978 1095.37 164.978 1102.5 Q164.978 1109.61 166.784 1113.17 Q168.613 1116.72 172.224 1116.72 Q175.858 1116.72 177.664 1113.17 Q179.492 1109.61 179.492 1102.5 Q179.492 1095.37 177.664 1091.83 Q175.858 1088.27 172.224 1088.27 M172.224 1084.56 Q178.034 1084.56 181.089 1089.17 Q184.168 1093.75 184.168 1102.5 Q184.168 1111.23 181.089 1115.84 Q178.034 1120.42 172.224 1120.42 Q166.414 1120.42 163.335 1115.84 Q160.279 1111.23 160.279 1102.5 Q160.279 1093.75 163.335 1089.17 Q166.414 1084.56 172.224 1084.56 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M192.386 1113.87 L197.27 1113.87 L197.27 1119.75 L192.386 1119.75 L192.386 1113.87 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M211.483 1115.81 L227.802 1115.81 L227.802 1119.75 L205.858 1119.75 L205.858 1115.81 Q208.52 1113.06 213.103 1108.43 Q217.71 1103.78 218.89 1102.43 Q221.136 1099.91 222.015 1098.17 Q222.918 1096.41 222.918 1094.72 Q222.918 1091.97 220.974 1090.23 Q219.052 1088.5 215.95 1088.5 Q213.751 1088.5 211.298 1089.26 Q208.867 1090.03 206.089 1091.58 L206.089 1086.85 Q208.913 1085.72 211.367 1085.14 Q213.821 1084.56 215.858 1084.56 Q221.228 1084.56 224.423 1087.25 Q227.617 1089.93 227.617 1094.42 Q227.617 1096.55 226.807 1098.47 Q226.02 1100.37 223.913 1102.97 Q223.335 1103.64 220.233 1106.85 Q217.131 1110.05 211.483 1115.81 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M237.663 1085.19 L256.02 1085.19 L256.02 1089.12 L241.946 1089.12 L241.946 1097.59 Q242.964 1097.25 243.983 1097.09 Q245.001 1096.9 246.02 1096.9 Q251.807 1096.9 255.186 1100.07 Q258.566 1103.24 258.566 1108.66 Q258.566 1114.24 255.094 1117.34 Q251.621 1120.42 245.302 1120.42 Q243.126 1120.42 240.858 1120.05 Q238.612 1119.68 236.205 1118.94 L236.205 1114.24 Q238.288 1115.37 240.51 1115.93 Q242.733 1116.48 245.209 1116.48 Q249.214 1116.48 251.552 1114.38 Q253.89 1112.27 253.89 1108.66 Q253.89 1105.05 251.552 1102.94 Q249.214 1100.84 245.209 1100.84 Q243.335 1100.84 241.46 1101.25 Q239.608 1101.67 237.663 1102.55 L237.663 1085.19 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M171.228 876.01 Q167.617 876.01 165.789 879.575 Q163.983 883.117 163.983 890.246 Q163.983 897.353 165.789 900.917 Q167.617 904.459 171.228 904.459 Q174.863 904.459 176.668 900.917 Q178.497 897.353 178.497 890.246 Q178.497 883.117 176.668 879.575 Q174.863 876.01 171.228 876.01 M171.228 872.307 Q177.039 872.307 180.094 876.913 Q183.173 881.496 183.173 890.246 Q183.173 898.973 180.094 903.58 Q177.039 908.163 171.228 908.163 Q165.418 908.163 162.34 903.58 Q159.284 898.973 159.284 890.246 Q159.284 881.496 162.34 876.913 Q165.418 872.307 171.228 872.307 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M191.39 901.612 L196.275 901.612 L196.275 907.492 L191.39 907.492 L191.39 901.612 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M216.46 876.01 Q212.849 876.01 211.02 879.575 Q209.214 883.117 209.214 890.246 Q209.214 897.353 211.02 900.917 Q212.849 904.459 216.46 904.459 Q220.094 904.459 221.899 900.917 Q223.728 897.353 223.728 890.246 Q223.728 883.117 221.899 879.575 Q220.094 876.01 216.46 876.01 M216.46 872.307 Q222.27 872.307 225.325 876.913 Q228.404 881.496 228.404 890.246 Q228.404 898.973 225.325 903.58 Q222.27 908.163 216.46 908.163 Q210.649 908.163 207.571 903.58 Q204.515 898.973 204.515 890.246 Q204.515 881.496 207.571 876.913 Q210.649 872.307 216.46 872.307 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M246.622 876.01 Q243.01 876.01 241.182 879.575 Q239.376 883.117 239.376 890.246 Q239.376 897.353 241.182 900.917 Q243.01 904.459 246.622 904.459 Q250.256 904.459 252.061 900.917 Q253.89 897.353 253.89 890.246 Q253.89 883.117 252.061 879.575 Q250.256 876.01 246.622 876.01 M246.622 872.307 Q252.432 872.307 255.487 876.913 Q258.566 881.496 258.566 890.246 Q258.566 898.973 255.487 903.58 Q252.432 908.163 246.622 908.163 Q240.811 908.163 237.733 903.58 Q234.677 898.973 234.677 890.246 Q234.677 881.496 237.733 876.913 Q240.811 872.307 246.622 872.307 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M172.224 663.754 Q168.613 663.754 166.784 667.319 Q164.978 670.861 164.978 677.99 Q164.978 685.097 166.784 688.661 Q168.613 692.203 172.224 692.203 Q175.858 692.203 177.664 688.661 Q179.492 685.097 179.492 677.99 Q179.492 670.861 177.664 667.319 Q175.858 663.754 172.224 663.754 M172.224 660.05 Q178.034 660.05 181.089 664.657 Q184.168 669.24 184.168 677.99 Q184.168 686.717 181.089 691.323 Q178.034 695.907 172.224 695.907 Q166.414 695.907 163.335 691.323 Q160.279 686.717 160.279 677.99 Q160.279 669.24 163.335 664.657 Q166.414 660.05 172.224 660.05 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M192.386 689.356 L197.27 689.356 L197.27 695.235 L192.386 695.235 L192.386 689.356 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M211.483 691.3 L227.802 691.3 L227.802 695.235 L205.858 695.235 L205.858 691.3 Q208.52 688.546 213.103 683.916 Q217.71 679.263 218.89 677.921 Q221.136 675.398 222.015 673.661 Q222.918 671.902 222.918 670.212 Q222.918 667.458 220.974 665.722 Q219.052 663.986 215.95 663.986 Q213.751 663.986 211.298 664.749 Q208.867 665.513 206.089 667.064 L206.089 662.342 Q208.913 661.208 211.367 660.629 Q213.821 660.05 215.858 660.05 Q221.228 660.05 224.423 662.736 Q227.617 665.421 227.617 669.911 Q227.617 672.041 226.807 673.962 Q226.02 675.861 223.913 678.453 Q223.335 679.124 220.233 682.342 Q217.131 685.536 211.483 691.3 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M237.663 660.675 L256.02 660.675 L256.02 664.611 L241.946 664.611 L241.946 673.083 Q242.964 672.736 243.983 672.574 Q245.001 672.388 246.02 672.388 Q251.807 672.388 255.186 675.56 Q258.566 678.731 258.566 684.148 Q258.566 689.726 255.094 692.828 Q251.621 695.907 245.302 695.907 Q243.126 695.907 240.858 695.536 Q238.612 695.166 236.205 694.425 L236.205 689.726 Q238.288 690.86 240.51 691.416 Q242.733 691.972 245.209 691.972 Q249.214 691.972 251.552 689.865 Q253.89 687.759 253.89 684.148 Q253.89 680.536 251.552 678.43 Q249.214 676.324 245.209 676.324 Q243.335 676.324 241.46 676.74 Q239.608 677.157 237.663 678.036 L237.663 660.675 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M171.228 451.498 Q167.617 451.498 165.789 455.063 Q163.983 458.604 163.983 465.734 Q163.983 472.841 165.789 476.405 Q167.617 479.947 171.228 479.947 Q174.863 479.947 176.668 476.405 Q178.497 472.841 178.497 465.734 Q178.497 458.604 176.668 455.063 Q174.863 451.498 171.228 451.498 M171.228 447.794 Q177.039 447.794 180.094 452.401 Q183.173 456.984 183.173 465.734 Q183.173 474.461 180.094 479.067 Q177.039 483.651 171.228 483.651 Q165.418 483.651 162.34 479.067 Q159.284 474.461 159.284 465.734 Q159.284 456.984 162.34 452.401 Q165.418 447.794 171.228 447.794 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M191.39 477.1 L196.275 477.1 L196.275 482.979 L191.39 482.979 L191.39 477.1 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M206.506 448.419 L224.862 448.419 L224.862 452.355 L210.788 452.355 L210.788 460.827 Q211.807 460.479 212.825 460.317 Q213.844 460.132 214.862 460.132 Q220.649 460.132 224.029 463.304 Q227.409 466.475 227.409 471.891 Q227.409 477.47 223.936 480.572 Q220.464 483.651 214.145 483.651 Q211.969 483.651 209.7 483.28 Q207.455 482.91 205.048 482.169 L205.048 477.47 Q207.131 478.604 209.353 479.16 Q211.575 479.715 214.052 479.715 Q218.057 479.715 220.395 477.609 Q222.733 475.503 222.733 471.891 Q222.733 468.28 220.395 466.174 Q218.057 464.067 214.052 464.067 Q212.177 464.067 210.302 464.484 Q208.45 464.901 206.506 465.78 L206.506 448.419 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M246.622 451.498 Q243.01 451.498 241.182 455.063 Q239.376 458.604 239.376 465.734 Q239.376 472.841 241.182 476.405 Q243.01 479.947 246.622 479.947 Q250.256 479.947 252.061 476.405 Q253.89 472.841 253.89 465.734 Q253.89 458.604 252.061 455.063 Q250.256 451.498 246.622 451.498 M246.622 447.794 Q252.432 447.794 255.487 452.401 Q258.566 456.984 258.566 465.734 Q258.566 474.461 255.487 479.067 Q252.432 483.651 246.622 483.651 Q240.811 483.651 237.733 479.067 Q234.677 474.461 234.677 465.734 Q234.677 456.984 237.733 452.401 Q240.811 447.794 246.622 447.794 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M21.7677 867.402 L39.6235 867.402 L39.6235 859.318 Q39.6235 854.83 37.3 852.379 Q34.9765 849.929 30.6797 849.929 Q26.4147 849.929 24.0912 852.379 Q21.7677 854.83 21.7677 859.318 L21.7677 867.402 M16.4842 873.832 L16.4842 859.318 Q16.4842 851.329 20.1126 847.255 Q23.7092 843.149 30.6797 843.149 Q37.7138 843.149 41.3104 847.255 Q44.907 851.329 44.907 859.318 L44.907 867.402 L64.0042 867.402 L64.0042 873.832 L16.4842 873.832 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M20.1444 798.939 L26.9239 798.939 Q23.9002 802.186 22.4043 805.878 Q20.9083 809.538 20.9083 813.676 Q20.9083 821.824 25.9054 826.153 Q30.8707 830.481 40.2919 830.481 Q49.6813 830.481 54.6784 826.153 Q59.6436 821.824 59.6436 813.676 Q59.6436 809.538 58.1477 805.878 Q56.6518 802.186 53.6281 798.939 L60.3439 798.939 Q62.6355 802.313 63.7814 806.101 Q64.9272 809.856 64.9272 814.058 Q64.9272 824.848 58.3387 831.054 Q51.7183 837.261 40.2919 837.261 Q28.8336 837.261 22.2451 831.054 Q15.6248 824.848 15.6248 814.058 Q15.6248 809.793 16.7706 806.037 Q17.8846 802.249 20.1444 798.939 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M38.3822 768.957 Q39.3689 764.342 42.4881 761.763 Q45.6073 759.154 50.1906 759.154 Q57.2247 759.154 61.0759 763.991 Q64.9272 768.829 64.9272 777.741 Q64.9272 780.733 64.3224 783.916 Q63.7495 787.067 62.5719 790.441 L56.3653 790.441 Q57.9249 787.767 58.7206 784.585 Q59.5163 781.402 59.5163 777.932 Q59.5163 771.885 57.1292 768.734 Q54.7421 765.551 50.1906 765.551 Q45.9892 765.551 43.6339 768.511 Q41.2468 771.439 41.2468 776.691 L41.2468 782.229 L35.9632 782.229 L35.9632 776.436 Q35.9632 771.694 34.0853 769.18 Q32.1756 766.665 28.6108 766.665 Q24.9505 766.665 23.009 769.275 Q21.0356 771.853 21.0356 776.691 Q21.0356 779.333 21.6086 782.357 Q22.1815 785.38 23.3909 789.009 L17.6618 789.009 Q16.6433 785.348 16.134 782.166 Q15.6248 778.951 15.6248 776.118 Q15.6248 768.798 18.9668 764.533 Q22.277 760.268 27.9424 760.268 Q31.8892 760.268 34.6264 762.527 Q37.3318 764.787 38.3822 768.957 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip602)" cx="1714.1" cy="668.824" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1669.12" cy="877.189" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1890.23" cy="993.789" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1789.73" cy="832.429" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1723.3" cy="681.493" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1739.2" cy="938.658" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1697.13" cy="906.945" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="2078.46" cy="1091.35" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1836.19" cy="873.532" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1876.57" cy="1035.34" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1846.54" cy="1028.56" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1713.62" cy="877.67" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1687.28" cy="630.447" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1839.84" cy="784.065" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1683.54" cy="884.886" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1829.87" cy="722.153" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="2048.05" cy="991.454" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1811.43" cy="710.806" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1846.16" cy="935.444" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1804.58" cy="782.262" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1523.07" cy="545.007" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1750.78" cy="1071.08" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1689.62" cy="764.187" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1710.36" cy="923.263" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1790.16" cy="774.565" r="14" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1206.61" cy="790.548" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1012.75" cy="654.46" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1040.3" cy="843.448" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1118.78" cy="830.579" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1061.02" cy="1052.14" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1154.05" cy="919.759" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1068.81" cy="751.735" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1261.21" cy="536.987" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1146.97" cy="582.144" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1108.5" cy="611.945" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1203.87" cy="613.305" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1067.66" cy="609.374" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1225.96" cy="535.185" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1086.91" cy="655.975" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1236.72" cy="544.972" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1124.55" cy="553.157" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="910.55" cy="811.935" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1178.38" cy="1140.35" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1048.21" cy="276.705" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1053.56" cy="758.399" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1110.04" cy="797.809" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1113.23" cy="728.443" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1153.24" cy="884.505" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1176.62" cy="632.792" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1123.64" cy="819.868" r="14" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="851.959" cy="1047.86" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="872.477" cy="885.239" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="848.697" cy="479.575" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="875.137" cy="424.835" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="977.372" cy="1143.37" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="899.389" cy="758.644" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="807.504" cy="1033.38" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="962.889" cy="1199.27" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="996.317" cy="896.253" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="838.993" cy="500.997" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="874.701" cy="1233.56" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="977.506" cy="740.035" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="984.002" cy="613.224" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1009.02" cy="996.277" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1004.12" cy="407.105" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1107.78" cy="687.843" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="985.134" cy="668.207" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="948.455" cy="490.325" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="948.97" cy="933.115" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1015.16" cy="811.973" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1058.4" cy="884.679" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="897.284" cy="1033.98" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="987.463" cy="938.939" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="986.656" cy="903.686" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="937.652" cy="1108.4" r="14" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<path clip-path="url(#clip600)" d="
M2001.41 300.469 L2283.91 300.469 L2283.91 93.1086 L2001.41 93.1086  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  2001.41,300.469 2283.91,300.469 2283.91,93.1086 2001.41,93.1086 2001.41,300.469 
  "/>
<circle clip-path="url(#clip600)" cx="2093.21" cy="144.949" r="23" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="5.12"/>
<path clip-path="url(#clip600)" d="M2198.85 164.636 Q2197.04 169.266 2195.33 170.678 Q2193.61 172.09 2190.74 172.09 L2187.34 172.09 L2187.34 168.525 L2189.84 168.525 Q2191.6 168.525 2192.57 167.692 Q2193.54 166.858 2194.73 163.756 L2195.49 161.812 L2185 136.303 L2189.52 136.303 L2197.62 156.581 L2205.72 136.303 L2210.23 136.303 L2198.85 164.636 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2217.53 158.293 L2225.16 158.293 L2225.16 131.928 L2216.85 133.595 L2216.85 129.335 L2225.12 127.669 L2229.79 127.669 L2229.79 158.293 L2237.43 158.293 L2237.43 162.229 L2217.53 162.229 L2217.53 158.293 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip600)" cx="2093.21" cy="196.789" r="23" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="5.12"/>
<path clip-path="url(#clip600)" d="M2198.85 216.476 Q2197.04 221.106 2195.33 222.518 Q2193.61 223.93 2190.74 223.93 L2187.34 223.93 L2187.34 220.365 L2189.84 220.365 Q2191.6 220.365 2192.57 219.532 Q2193.54 218.698 2194.73 215.596 L2195.49 213.652 L2185 188.143 L2189.52 188.143 L2197.62 208.421 L2205.72 188.143 L2210.23 188.143 L2198.85 216.476 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2220.74 210.133 L2237.06 210.133 L2237.06 214.069 L2215.12 214.069 L2215.12 210.133 Q2217.78 207.379 2222.36 202.749 Q2226.97 198.096 2228.15 196.754 Q2230.4 194.231 2231.28 192.495 Q2232.18 190.735 2232.18 189.046 Q2232.18 186.291 2230.23 184.555 Q2228.31 182.819 2225.21 182.819 Q2223.01 182.819 2220.56 183.583 Q2218.13 184.347 2215.35 185.897 L2215.35 181.175 Q2218.17 180.041 2220.63 179.462 Q2223.08 178.884 2225.12 178.884 Q2230.49 178.884 2233.68 181.569 Q2236.88 184.254 2236.88 188.745 Q2236.88 190.874 2236.07 192.796 Q2235.28 194.694 2233.17 197.286 Q2232.6 197.958 2229.49 201.175 Q2226.39 204.37 2220.74 210.133 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip600)" cx="2093.21" cy="248.629" r="23" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="5.12"/>
<path clip-path="url(#clip600)" d="M2198.85 268.316 Q2197.04 272.946 2195.33 274.358 Q2193.61 275.77 2190.74 275.77 L2187.34 275.77 L2187.34 272.205 L2189.84 272.205 Q2191.6 272.205 2192.57 271.372 Q2193.54 270.538 2194.73 267.436 L2195.49 265.492 L2185 239.983 L2189.52 239.983 L2197.62 260.261 L2205.72 239.983 L2210.23 239.983 L2198.85 268.316 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M2230.88 247.274 Q2234.24 247.992 2236.11 250.261 Q2238.01 252.529 2238.01 255.862 Q2238.01 260.978 2234.49 263.779 Q2230.98 266.58 2224.49 266.58 Q2222.32 266.58 2220 266.14 Q2217.71 265.723 2215.26 264.867 L2215.26 260.353 Q2217.2 261.487 2219.52 262.066 Q2221.83 262.645 2224.35 262.645 Q2228.75 262.645 2231.04 260.909 Q2233.36 259.173 2233.36 255.862 Q2233.36 252.807 2231.21 251.094 Q2229.08 249.358 2225.26 249.358 L2221.23 249.358 L2221.23 245.515 L2225.44 245.515 Q2228.89 245.515 2230.72 244.149 Q2232.55 242.761 2232.55 240.168 Q2232.55 237.506 2230.65 236.094 Q2228.78 234.659 2225.26 234.659 Q2223.34 234.659 2221.14 235.075 Q2218.94 235.492 2216.3 236.372 L2216.3 232.205 Q2218.96 231.464 2221.28 231.094 Q2223.61 230.724 2225.67 230.724 Q2231 230.724 2234.1 233.154 Q2237.2 235.562 2237.2 239.682 Q2237.2 242.552 2235.56 244.543 Q2233.91 246.511 2230.88 247.274 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /></svg>
<h2 id="Linear-Principal-Component-Analysis"><a class="docs-heading-anchor" href="#Linear-Principal-Component-Analysis">Linear Principal Component Analysis</a><a id="Linear-Principal-Component-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-Principal-Component-Analysis" title="Permalink"></a></h2><p>This package uses the <a href="#MultivariateStats.PCA"><code>PCA</code></a> type to define a linear PCA model:</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.PCA" href="#MultivariateStats.PCA"><code>MultivariateStats.PCA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Linear Principal Component Analysis</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L3-L5">source</a></section></article><p>This type comes with several methods where <span>$M$</span> be an instance of  <a href="#MultivariateStats.PCA"><code>PCA</code></a>, <span>$d$</span> be the dimension of observations, and <span>$p$</span> be the output dimension (<em>i.e</em> the dimension of the principal subspace).</p><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit-Union{Tuple{T}, Tuple{Type{PCA}, AbstractMatrix{T}}} where T&lt;:Real" href="#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{PCA}, AbstractMatrix{T}}} where T&lt;:Real"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit(PCA, X; ...)</code></pre><p>Perform PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an <strong>observation</strong>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:auto</code>: use <code>:cov</code> when <code>d &lt; n</code> or <code>:svd</code> otherwise (<em>default</em>).</li><li><code>:cov</code>: based on covariance matrix decomposition.</li><li><code>:svd</code>: based on SVD of the input data.</li></ul></li><li><code>maxoutdim</code>: The output dimension, i.e. dimension of the transformed space (<em>min(d, nc-1)</em>)</li><li><code>pratio</code>: The ratio of variances preserved in the principal subspace (<em>0.99</em>)</li><li><code>mean</code>: The mean vector, which can be either of<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li></ul><p><strong>Notes:</strong></p><ul><li><p>The output dimension <code>p</code> depends on both <code>maxoutdim</code> and <code>pratio</code>, as follows. Suppose the first <code>k</code> principal components preserve at least <code>pratio</code> of the total variance, while the first <code>k-1</code> preserves less than <code>pratio</code>, then the actual output dimension will be <span>$\min(k, maxoutdim)$</span>.</p></li><li><p>This function calls <a href="#MultivariateStats.pcacov"><code>pcacov</code></a> or <a href="#MultivariateStats.pcasvd"><code>pcasvd</code></a> internally, depending on the choice of method.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L255-L280">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.predict-Union{Tuple{T}, Tuple{PCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#StatsAPI.predict-Union{Tuple{T}, Tuple{PCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>StatsAPI.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(M::PCA, x::AbstractVecOrMat{&lt;:Real})</code></pre><p>Given a PCA model <code>M</code>, transform observations <code>x</code> into principal components space, as</p><p class="math-container">\[\mathbf{y} = \mathbf{P}^T (\mathbf{x} - \boldsymbol{\mu})\]</p><p>Here, <code>x</code> can be either a vector of length <code>d</code> or a matrix where each column is an observation, and <code>\mathbf{P}</code> is the projection matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L112-L121">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{PCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{PCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>MultivariateStats.reconstruct</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reconstruct(M::PCA, y::AbstractVecOrMat{&lt;:Real})</code></pre><p>Given a PCA model <code>M</code>, returns a (approximately) reconstructed observations from principal components space, as</p><p class="math-container">\[\tilde{\mathbf{x}} = \mathbf{P} \mathbf{y} + \boldsymbol{\mu}\]</p><p>Here, <code>y</code> can be either a vector of length <code>p</code> or a matrix where each column gives the principal components for an observation, and <span>$\mathbf{P}$</span> is the projection matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L124-L134">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.size-Tuple{PCA}" href="#Base.size-Tuple{PCA}"><code>Base.size</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">size(M)</code></pre><p>Returns a tuple with the dimensions of input (the dimension of the observation space) and output (the dimension of the principal subspace).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.mean-Tuple{PCA}" href="#Statistics.mean-Tuple{PCA}"><code>Statistics.mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mean(M::PCA)</code></pre><p>Returns the mean vector (of length <code>d</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L36-L40">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.projection-Tuple{PCA}" href="#MultivariateStats.projection-Tuple{PCA}"><code>MultivariateStats.projection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">projection(M::PCA)</code></pre><p>Returns the projection matrix (of size <code>(d, p)</code>). Each column of the projection matrix corresponds to a principal component. The principal components are arranged in descending order of the corresponding variances.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L43-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.var-Tuple{PCA}" href="#Statistics.var-Tuple{PCA}"><code>Statistics.var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">var(M::PCA)</code></pre><p>Returns the total observation variance, which is equal to <code>tprincipalvar(M) + tresidualvar(M)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L87-L91">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.principalvars-Tuple{PCA}" href="#MultivariateStats.principalvars-Tuple{PCA}"><code>MultivariateStats.principalvars</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">principalvars(M::PCA)</code></pre><p>Returns the variances of principal components.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L58-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.tprincipalvar-Tuple{PCA}" href="#MultivariateStats.tprincipalvar-Tuple{PCA}"><code>MultivariateStats.tprincipalvar</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tprincipalvar(M::PCA)</code></pre><p>Returns the total variance of principal components, which is equal to <code>sum(principalvars(M))</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L73-L77">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.tresidualvar-Tuple{PCA}" href="#MultivariateStats.tresidualvar-Tuple{PCA}"><code>MultivariateStats.tresidualvar</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tresidualvar(M::PCA)</code></pre><p>Returns the total residual variance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L80-L84">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.r2-Tuple{PCA}" href="#StatsAPI.r2-Tuple{PCA}"><code>StatsAPI.r2</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">r2(M::PCA)
principalratio(M::PCA)</code></pre><p>Returns the ratio of variance preserved in the principal subspace, which is equal to <code>tprincipalvar(M) / var(M)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L94-L99">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.loadings-Tuple{PCA}" href="#MultivariateStats.loadings-Tuple{PCA}"><code>MultivariateStats.loadings</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">loadings(M::PCA)</code></pre><p>Returns model loadings, i.e. the weights for each original variable when calculating the principal component.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L103-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvals-Tuple{PCA}" href="#LinearAlgebra.eigvals-Tuple{PCA}"><code>LinearAlgebra.eigvals</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eigvals(M::PCA)</code></pre><p>Get the eigenvalues of the PCA model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L66-L70">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvecs-Tuple{PCA}" href="#LinearAlgebra.eigvecs-Tuple{PCA}"><code>LinearAlgebra.eigvecs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eigvecs(M::PCA)</code></pre><p>Get the eigenvalues of the PCA model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L51-L55">source</a></section></article><p>Auxiliary functions:</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.pcacov" href="#MultivariateStats.pcacov"><code>MultivariateStats.pcacov</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pcacov(C, mean; ...)</code></pre><p>Compute and return a PCA model based on eigenvalue decomposition of a given covariance matrix <code>C</code>.</p><p><strong>Parameters:</strong></p><ul><li><code>C</code>: The covariance matrix of the samples.</li><li><code>mean</code>: The mean vector of original samples, which can be a vector of length <code>d</code>,          or an empty vector <code>Float64[]</code> indicating a zero mean.</li></ul><p><em>Note:</em> This function accepts two keyword arguments: <code>maxoutdim</code> and <code>pratio</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L197-L208">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.pcasvd" href="#MultivariateStats.pcasvd"><code>MultivariateStats.pcasvd</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pcasvd(Z, mean, tw; ...)</code></pre><p>Compute and return a PCA model based on singular value decomposition of a centralized sample matrix <code>Z</code>.</p><p><strong>Parameters:</strong></p><ul><li><code>Z</code>: a matrix of centralized samples.</li><li><code>mean</code>: The mean vector of the <strong>original</strong> samples, which can be a vector of length <code>d</code>,         or an empty vector <code>Float64[]</code> indicating a zero mean.</li><li><code>n</code>: a number of samples.</li></ul><p><em>Note:</em> This function accepts two keyword arguments: <code>maxoutdim</code> and <code>pratio</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L223-L235">source</a></section></article><h2 id="Kernel-Principal-Component-Analysis"><a class="docs-heading-anchor" href="#Kernel-Principal-Component-Analysis">Kernel Principal Component Analysis</a><a id="Kernel-Principal-Component-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-Principal-Component-Analysis" title="Permalink"></a></h2><p><a href="https://en.wikipedia.org/wiki/Kernel_principal_component_analysis&gt;">Kernel Principal Component Analysis</a> (kernel PCA) is an extension of principal component analysis (PCA) using techniques of kernel methods. Using a kernel, the originally linear operations of PCA are performed in a reproducing kernel Hilbert space.</p><p>This package defines a <a href="#MultivariateStats.KernelPCA"><code>KernelPCA</code></a> type to represent a kernel PCA model.</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.KernelPCA" href="#MultivariateStats.KernelPCA"><code>MultivariateStats.KernelPCA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This type contains kernel PCA model parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L31-L33">source</a></section></article><p>The package provides a set of methods to access the properties of the kernel PCA model. Let <span>$M$</span> be an instance of <a href="#MultivariateStats.KernelPCA"><code>KernelPCA</code></a>, <span>$d$</span> be the dimension of observations, and <span>$p$</span> be the output dimension (<em>i.e</em> the dimension of the principal subspace).</p><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit-Union{Tuple{T}, Tuple{Type{KernelPCA}, AbstractMatrix{T}}} where T&lt;:Real" href="#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{KernelPCA}, AbstractMatrix{T}}} where T&lt;:Real"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit(KernelPCA, X; ...)</code></pre><p>Perform kernel PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an observation.</p><p>This method returns an instance of <a href="#MultivariateStats.KernelPCA"><code>KernelPCA</code></a>.</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>kernel</code>: The kernel function. This functions accepts two vector arguments <code>x</code> and <code>y</code>,</li></ul><p>and returns a scalar value (<em>default:</em> <code>(x,y)-&gt;x&#39;y</code>)</p><ul><li><code>solver</code>: The choice of solver:<ul><li><code>:eig</code>: uses <code>LinearAlgebra.eigen</code> (<em>default</em>)</li><li><code>:eigs</code>: uses <code>Arpack.eigs</code> (always used for sparse data)</li></ul></li><li><code>maxoutdim</code>:  Maximum output dimension (<em>default</em> <code>min(d, n)</code>)</li><li><code>inverse</code>: Whether to perform calculation for inverse transform for non-precomputed kernels (<em>default</em> <code>false</code>)</li><li><code>β</code>: Hyperparameter of the ridge regression that learns the inverse transform (<em>default</em> <code>1</code> when <code>inverse</code> is <code>true</code>).</li><li><code>tol</code>: Convergence tolerance for <code>eigs</code> solver (<em>default</em> <code>0.0</code>)</li><li><code>maxiter</code>: Maximum number of iterations for <code>eigs</code> solver (<em>default</em> <code>300</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L123-L144">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.predict-Tuple{KernelPCA}" href="#StatsAPI.predict-Tuple{KernelPCA}"><code>StatsAPI.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(M::KernelPCA)</code></pre><p>Transform the data fitted to the model <code>M</code> to a kernel space of the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L91-L95">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.predict-Union{Tuple{T}, Tuple{KernelPCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#StatsAPI.predict-Union{Tuple{T}, Tuple{KernelPCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>StatsAPI.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(M::KernelPCA, x)</code></pre><p>Transform out-of-sample transformation of <code>x</code> into a kernel space of the model <code>M</code>.</p><p>Here, <code>x</code> can be either a vector of length <code>d</code> or a matrix where each column is an observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L77-L83">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{KernelPCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{KernelPCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>MultivariateStats.reconstruct</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reconstruct(M::KernelPCA, y)</code></pre><p>Approximately reconstruct observations, given in <code>y</code>, to the original space using the kernel PCA model <code>M</code>.</p><p>Here, <code>y</code> can be either a vector of length <code>p</code> or a matrix where each column gives the principal components for an observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L99-L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.size-Tuple{KernelPCA}" href="#Base.size-Tuple{KernelPCA}"><code>Base.size</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">size(M::KernelPCA)</code></pre><p>Returns a tuple with the input dimension <span>$d$</span>, <em>i.e</em> the dimension of the observation space, and the output dimension <span>$p$</span>, <em>i.e</em> the dimension of the principal subspace.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L44-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.projection-Tuple{KernelPCA}" href="#MultivariateStats.projection-Tuple{KernelPCA}"><code>MultivariateStats.projection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">projection(M::KernelPCA)</code></pre><p>Return the projection matrix (of size <span>$n \times p$</span>). Each column of the projection matrix corresponds to an eigenvector, and <span>$n$</span> is a number of observations.</p><p>The principal components are arranged in descending order of the corresponding eigenvalues.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L65-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvals-Tuple{KernelPCA}" href="#LinearAlgebra.eigvals-Tuple{KernelPCA}"><code>LinearAlgebra.eigvals</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eigvals(M::KernelPCA)</code></pre><p>Return eigenvalues of the kernel matrix of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L51-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvecs-Tuple{KernelPCA}" href="#LinearAlgebra.eigvecs-Tuple{KernelPCA}"><code>LinearAlgebra.eigvecs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eigvecs(M::KernelPCA)</code></pre><p>Return eigenvectors of the kernel matrix of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L58-L62">source</a></section></article><h3 id="Kernels"><a class="docs-heading-anchor" href="#Kernels">Kernels</a><a id="Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Kernels" title="Permalink"></a></h3><p>List of the commonly used kernels:</p><table><tr><th style="text-align: right">function</th><th style="text-align: right">description</th></tr><tr><td style="text-align: right"><code>(x,y)-&gt;x&#39;y</code></td><td style="text-align: right">Linear</td></tr><tr><td style="text-align: right"><code>(x,y)-&gt;(x&#39;y+c)^d</code></td><td style="text-align: right">Polynomial</td></tr><tr><td style="text-align: right"><code>(x,y)-&gt;exp(-γ*norm(x-y)^2.0)</code></td><td style="text-align: right">Radial basis function (RBF)</td></tr></table><p>This package has a separate interface for adjusting kernel matrices.</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.KernelCenter" href="#MultivariateStats.KernelCenter"><code>MultivariateStats.KernelCenter</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Center a kernel matrix</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit-Tuple{Type{MultivariateStats.KernelCenter}, AbstractMatrix{&lt;:Real}}" href="#StatsAPI.fit-Tuple{Type{MultivariateStats.KernelCenter}, AbstractMatrix{&lt;:Real}}"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Fit <code>KernelCenter</code> object</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.transform!-Tuple{MultivariateStats.KernelCenter, AbstractMatrix{&lt;:Real}}" href="#MultivariateStats.transform!-Tuple{MultivariateStats.KernelCenter, AbstractMatrix{&lt;:Real}}"><code>MultivariateStats.transform!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Center kernel matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L18">source</a></section></article><h2 id="Probabilistic-Principal-Component-Analysis"><a class="docs-heading-anchor" href="#Probabilistic-Principal-Component-Analysis">Probabilistic Principal Component Analysis</a><a id="Probabilistic-Principal-Component-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilistic-Principal-Component-Analysis" title="Permalink"></a></h2><p><a href="https://www.microsoft.com/en-us/research/publication/probabilistic-principal-component-analysis">Probabilistic Principal Component Analysis</a> (PPCA) represents a constrained form of the Gaussian distribution in which the number of free parameters can be restricted while still allowing the model to capture the dominant correlations in a data set. It is expressed as the maximum likelihood solution of a probabilistic latent variable model<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>.</p><p>This package defines a <a href="#MultivariateStats.PPCA"><code>PPCA</code></a> type to represent a probabilistic PCA model, and provides a set of methods to access the properties.</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.PPCA" href="#MultivariateStats.PPCA"><code>MultivariateStats.PPCA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This type contains probabilistic PCA model parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L3-L5">source</a></section></article><p>Let <span>$M$</span> be an instance of <a href="#MultivariateStats.PPCA"><code>PPCA</code></a>, <span>$d$</span> be the dimension of observations, and <span>$p$</span> be the output dimension (<em>i.e</em> the dimension of the principal subspace).</p><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit" href="#StatsAPI.fit"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">fit(Whitening, X::AbstractMatrix{T}; kwargs...)</code></pre><p>Estimate a whitening transform from the data given in <code>X</code>.</p><p>This function returns an instance of <a href="../whiten/#MultivariateStats.Whitening"><code>Whitening</code></a></p><p><strong>Keyword Arguments:</strong></p><ul><li><p><code>regcoef</code>: The regularization coefficient. The covariance will be regularized as follows when <code>regcoef</code> is positive <code>C + (eigmax(C) * regcoef) * eye(d)</code>. Default values is <code>zero(T)</code>.</p></li><li><p><code>dims</code>: if <code>1</code> the transformation calculated from the row samples. fit standardization parameters in column-wise fashion; if <code>2</code> the transformation calculated from the column samples. The default is <code>nothing</code>, which is equivalent to <code>dims=2</code> with a deprecation warning.</p></li><li><p><code>mean</code>: The mean vector, which can be either of:</p><ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<strong>default</strong>)</li><li>a pre-computed mean vector</li></ul></li></ul><p><strong>Note:</strong> This function internally relies on <a href="../whiten/#MultivariateStats.cov_whitening"><code>cov_whitening</code></a> to derive the transformation <code>W</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/whiten.jl#L104-L123">source</a></section><section><div><pre><code class="language-julia hljs">fit(PCA, X; ...)</code></pre><p>Perform PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an <strong>observation</strong>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:auto</code>: use <code>:cov</code> when <code>d &lt; n</code> or <code>:svd</code> otherwise (<em>default</em>).</li><li><code>:cov</code>: based on covariance matrix decomposition.</li><li><code>:svd</code>: based on SVD of the input data.</li></ul></li><li><code>maxoutdim</code>: The output dimension, i.e. dimension of the transformed space (<em>min(d, nc-1)</em>)</li><li><code>pratio</code>: The ratio of variances preserved in the principal subspace (<em>0.99</em>)</li><li><code>mean</code>: The mean vector, which can be either of<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li></ul><p><strong>Notes:</strong></p><ul><li><p>The output dimension <code>p</code> depends on both <code>maxoutdim</code> and <code>pratio</code>, as follows. Suppose the first <code>k</code> principal components preserve at least <code>pratio</code> of the total variance, while the first <code>k-1</code> preserves less than <code>pratio</code>, then the actual output dimension will be <span>$\min(k, maxoutdim)$</span>.</p></li><li><p>This function calls <a href="#MultivariateStats.pcacov"><code>pcacov</code></a> or <a href="#MultivariateStats.pcasvd"><code>pcasvd</code></a> internally, depending on the choice of method.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/pca.jl#L255-L280">source</a></section><section><div><pre><code class="nohighlight hljs">fit(PPCA, X; ...)</code></pre><p>Perform probabilistic PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an observation. This method returns an instance of <a href="#MultivariateStats.PPCA"><code>PPCA</code></a>.</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:ml</code>: use maximum likelihood version of probabilistic PCA (<em>default</em>)</li><li><code>:em</code>: use EM version of probabilistic PCA</li><li><code>:bayes</code>: use Bayesian PCA</li></ul></li><li><code>maxoutdim</code>: Maximum output dimension (<em>default</em> <code>d-1</code>)</li><li><code>mean</code>: The mean vector, which can be either of:<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li><li><code>tol</code>: Convergence tolerance (<em>default</em> <code>1.0e-6</code>)</li><li><code>maxiter</code>: Maximum number of iterations (<em>default</em> <code>1000</code>)</li></ul><p><strong>Notes:</strong> This function calls <a href="#MultivariateStats.ppcaml"><code>ppcaml</code></a>, <a href="#MultivariateStats.ppcaem"><code>ppcaem</code></a> or <a href="#MultivariateStats.bayespca"><code>bayespca</code></a> internally, depending on the choice of method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L280-L305">source</a></section><section><div><p>Fit <code>KernelCenter</code> object</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L11">source</a></section><section><div><pre><code class="language-julia hljs">fit(KernelPCA, X; ...)</code></pre><p>Perform kernel PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an observation.</p><p>This method returns an instance of <a href="#MultivariateStats.KernelPCA"><code>KernelPCA</code></a>.</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>kernel</code>: The kernel function. This functions accepts two vector arguments <code>x</code> and <code>y</code>,</li></ul><p>and returns a scalar value (<em>default:</em> <code>(x,y)-&gt;x&#39;y</code>)</p><ul><li><code>solver</code>: The choice of solver:<ul><li><code>:eig</code>: uses <code>LinearAlgebra.eigen</code> (<em>default</em>)</li><li><code>:eigs</code>: uses <code>Arpack.eigs</code> (always used for sparse data)</li></ul></li><li><code>maxoutdim</code>:  Maximum output dimension (<em>default</em> <code>min(d, n)</code>)</li><li><code>inverse</code>: Whether to perform calculation for inverse transform for non-precomputed kernels (<em>default</em> <code>false</code>)</li><li><code>β</code>: Hyperparameter of the ridge regression that learns the inverse transform (<em>default</em> <code>1</code> when <code>inverse</code> is <code>true</code>).</li><li><code>tol</code>: Convergence tolerance for <code>eigs</code> solver (<em>default</em> <code>0.0</code>)</li><li><code>maxiter</code>: Maximum number of iterations for <code>eigs</code> solver (<em>default</em> <code>300</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/kpca.jl#L123-L144">source</a></section><section><div><pre><code class="language-julia hljs">fit(CCA, X, Y; ...)</code></pre><p>Perform CCA over the data given in matrices <code>X</code> and <code>Y</code>. Each column of <code>X</code> and <code>Y</code> is an observation.</p><p><code>X</code> and <code>Y</code> should have the same number of columns (denoted by <code>n</code> below).</p><p>This method returns an instance of <a href="../cca/#MultivariateStats.CCA"><code>CCA</code></a>.</p><p><strong>Keyword arguments:</strong></p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:cov</code>: based on covariance matrices</li><li><code>:svd</code>: based on SVD of the input data (<em>default</em>)</li></ul></li><li><code>outdim</code>: The output dimension, <em>i.e</em> dimension of the common space (<em>default</em>: <code>min(dx, dy, n)</code>)</li><li><code>mean</code>: The mean vector, which can be either of:<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li></ul><p><strong>Notes:</strong> This function calls <a href="../cca/#MultivariateStats.ccacov"><code>ccacov</code></a> or <a href="../cca/#MultivariateStats.ccasvd"><code>ccasvd</code></a> internally, depending on the choice of method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/cca.jl#L283-L304">source</a></section><section><div><pre><code class="language-julia hljs">fit(MDS, X; kwargs...)</code></pre><p>Compute an embedding of <code>X</code> points by classical multidimensional scaling (MDS). There are two calling options, specified via the required keyword argument <code>distances</code>:</p><pre><code class="nohighlight hljs">mds = fit(MDS, X; distances=false, maxoutdim=size(X,1)-1)</code></pre><p>where <code>X</code> is the data matrix. Distances between pairs of columns of <code>X</code> are computed using the Euclidean norm. This is equivalent to performing PCA on <code>X</code>.</p><pre><code class="nohighlight hljs">mds = fit(MDS, D; distances=true, maxoutdim=size(D,1)-1)</code></pre><p>where <code>D</code> is a symmetric matrix <code>D</code> of distances between points.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/cmds.jl#L217-L231">source</a></section><section><div><pre><code class="language-julia hljs">fit(LinearDiscriminant, Xp, Xn; covestimator = SimpleCovariance())</code></pre><p>Performs LDA given both positive and negative samples. The function accepts follwing parameters:</p><p><strong>Parameters</strong></p><ul><li><code>Xp</code>: The sample matrix of the positive class.</li><li><code>Xn</code>: The sample matrix of the negative class.</li></ul><p><strong>Keyword arguments:</strong></p><ul><li><code>covestimator</code>: Custom covariance estimator for between-class covariance. The covariance matrix will be calculated as <code>cov(covestimator_between, #=data=#; dims=2, mean=zeros(#=...=#)</code>. Custom covariance estimators, available in other packages, may result in more robust discriminants for data with more features than observations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/lda.jl#L128-L139">source</a></section><section><div><pre><code class="language-julia hljs">fit(MulticlassLDA, nc, X, y; ...)</code></pre><p>Perform multi-class LDA over a given data set <code>X</code> and collecttion of labels <code>y</code>.</p><p>This function returns the resultant multi-class LDA model as an instance of <a href="../lda/#MultivariateStats.MulticlassLDA"><code>MulticlassLDA</code></a>.</p><p><em>Parameters</em></p><ul><li><code>nc</code>:  the number of classes</li><li><code>X</code>:   the matrix of input samples, of size <code>(d, n)</code>. Each column in <code>X</code> is an observation.</li><li><code>y</code>:   the vector of class labels, of length <code>n</code>. Each element of <code>y</code> must be an integer between <code>1</code> and <code>nc</code>.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:gevd</code>: based on generalized eigenvalue decomposition (<em>default</em>).</li><li><code>:whiten</code>: first derive a whitening transform from <code>Sw</code> and then solve the problem based on eigenvalue</li></ul>decomposition of the whiten <code>Sb</code>.</li><li><code>outdim</code>: The output dimension, i.e. dimension of the transformed space <code>min(d, nc-1)</code></li><li><code>regcoef</code>: The regularization coefficient (<em>default:</em> <code>1.0e-6</code>). A positive value <code>regcoef * eigmax(Sw)</code>   is added to the diagonal of <code>Sw</code> to improve numerical stability.</li><li><code>covestimator_between</code>: Custom covariance estimator for between-class covariance (<em>default:</em> <code>SimpleCovariance()</code>).   The covariance matrix will be calculated as <code>cov(covestimator_between, #=data=#; dims=2, mean=zeros(#=...=#))</code>.   Custom covariance estimators, available in other packages, may result in more robust discriminants for data   with more features than observations.</li><li><code>covestimator_within</code>:  Custom covariance estimator for within-class covariance (<em>default:</em> <code>SimpleCovariance()</code>).   The covariance matrix will be calculated as <code>cov(covestimator_within, #=data=#; dims=2, mean=zeros(nc))</code>.   Custom covariance estimators, available in other packages, may result in more robust discriminants for data   with more features than observations.</li></ul><p><strong>Notes:</strong></p><p>The resultant projection matrix <span>$P$</span> satisfies:</p><p class="math-container">\[\mathbf{P}^T (\mathbf{S}_w + \kappa \mathbf{I}) \mathbf{P} = \mathbf{I}\]</p><p>Here, <span>$\kappa$</span> equals <code>regcoef * eigmax(Sw)</code>. The columns of <span>$P$</span> are arranged in descending order of the corresponding generalized eigenvalues.</p><p>Note that <a href="../lda/#MultivariateStats.MulticlassLDA"><code>MulticlassLDA</code></a> does not currently support the normalized version using <span>$\mathbf{S}_w^*$</span> and <span>$\mathbf{S}_b^*$</span> (see <a href="../lda/#MultivariateStats.SubspaceLDA"><code>SubspaceLDA</code></a>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/lda.jl#L285-L327">source</a></section><section><div><pre><code class="language-julia hljs">fit(SubspaceLDA, X, labels; normalize=true)</code></pre><p>Fit an subspace projection of LDA model using the equivalent of <span>$\mathbf{S}_w^*$</span> and <span>$\mathbf{S}_b^*$</span>`.</p><p>Note: Subspace LDA also supports the normalized version of LDA via the <code>normalize</code> keyword.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/lda.jl#L454-L460">source</a></section><section><div><pre><code class="language-julia hljs">fit(ICA, X, k; ...)</code></pre><p>Perform ICA over the data set given in <code>X</code>.</p><p><strong>Parameters:</strong> -<code>X</code>: The data matrix, of size <span>$(m, n)$</span>. Each row corresponds to a mixed signal, while each column corresponds to an observation (<em>e.g</em> all signal value at a particular time step). -<code>k</code>: The number of independent components to recover.</p><p><strong>Keyword Arguments:</strong></p><ul><li><code>alg</code>: The choice of algorithm (<em>default</em> <code>:fastica</code>)</li><li><code>fun</code>: The approx neg-entropy functor (<em>default</em> <a href="../ica/#MultivariateStats.Tanh"><code>Tanh</code></a>)</li><li><code>do_whiten</code>: Whether to perform pre-whitening (<em>default</em> <code>true</code>)</li><li><code>maxiter</code>: Maximum number of iterations (<em>default</em> <code>100</code>)</li><li><code>tol</code>: Tolerable change of <span>$W$</span> at convergence (<em>default</em> <code>1.0e-6</code>)</li><li><code>mean</code>: The mean vector, which can be either of:<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li><li><code>winit</code>: Initial guess of <span>$W$</span>, which should be either of:<ul><li>empty matrix: the function will perform random initialization (<em>default</em>)</li><li>a matrix of size <span>$(k, k)$</span> (when <code>do_whiten</code>)</li><li>a matrix of size <span>$(m, k)$</span> (when <code>!do_whiten</code>)</li></ul></li></ul><p>Returns the resultant ICA model, an instance of type <a href="../ica/#MultivariateStats.ICA"><code>ICA</code></a>.</p><p><strong>Note:</strong> If <code>do_whiten</code> is <code>true</code>, the return <code>W</code> satisfies <span>$\mathbf{W}^T \mathbf{C} \mathbf{W} = \mathbf{I}$</span>, otherwise <span>$W$</span> is orthonormal, <em>i.e</em> <span>$\mathbf{W}^T \mathbf{W} = \mathbf{I}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ica.jl#L181-L211">source</a></section><section><div><pre><code class="language-julia hljs">fit(FactorAnalysis, X; ...)</code></pre><p>Perform factor analysis over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an observation. This method returns an instance of <a href="../fa/#MultivariateStats.FactorAnalysis"><code>FactorAnalysis</code></a>.</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:em</code>: use EM version of factor analysis</li><li><code>:cm</code>: use CM version of factor analysis (<em>default</em>)</li></ul></li><li><code>maxoutdim</code>: Maximum output dimension (<em>default</em> <code>d-1</code>)</li><li><code>mean</code>: The mean vector, which can be either of:<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li><li><code>tol</code>: Convergence tolerance (<em>default</em> <code>1.0e-6</code>)</li><li><code>maxiter</code>: Maximum number of iterations (<em>default</em> <code>1000</code>)</li><li><code>η</code>: Variance low bound (<em>default</em> <code>1.0e-6</code>)</li></ul><p><strong>Notes:</strong> This function calls <a href="../fa/#MultivariateStats.facm"><code>facm</code></a> or <a href="../fa/#MultivariateStats.faem"><code>faem</code></a> internally, depending on the choice of method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/fa.jl#L232-L256">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.size-Tuple{PPCA}" href="#Base.size-Tuple{PPCA}"><code>Base.size</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">size(M::PPCA)</code></pre><p>Returns a tuple with values of the input dimension <span>$d$</span>, <em>i.e</em> the dimension of the observation space, and the output dimension <span>$p$</span>, <em>i.e</em> the dimension of the principal subspace.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L13-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.mean-Tuple{PPCA}" href="#Statistics.mean-Tuple{PPCA}"><code>Statistics.mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mean(M::PPCA)</code></pre><p>Get the mean vector (of length <span>$d$</span>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L22-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.var-Tuple{PPCA}" href="#Statistics.var-Tuple{PPCA}"><code>Statistics.var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">var(M::PPCA)</code></pre><p>Returns the total residual variance of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L40-L44">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{PPCA}" href="#Statistics.cov-Tuple{PPCA}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">cov(M::PPCA)</code></pre><p>Returns the covariance of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L54-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.projection-Tuple{PPCA}" href="#MultivariateStats.projection-Tuple{PPCA}"><code>MultivariateStats.projection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">projection(M::PPCA)</code></pre><p>Returns the projection matrix (of size <span>$(d, p)$</span>). Each column of the projection matrix corresponds to a principal component.</p><p>The principal components are arranged in descending order of the corresponding variances.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L29-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.loadings-Tuple{PPCA}" href="#MultivariateStats.loadings-Tuple{PPCA}"><code>MultivariateStats.loadings</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">loadings(M::PPCA)</code></pre><p>Returns the factor loadings matrix (of size <span>$(d, p)$</span>) of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L47-L51">source</a></section></article><p>Given a probabilistic PCA model <span>$M$</span>, one can use it to transform observations into latent variables, as</p><pre><code class="language- hljs">\mathbf{z} = (\mathbf{W}^T \mathbf{W} + \sigma^2 \mathbf{I}) \mathbf{W}^T (\mathbf{x} - \boldsymbol{\mu})</code></pre><p>or use it to reconstruct (approximately) the observations from latent variables, as</p><pre><code class="language- hljs">\tilde{\mathbf{x}} = \mathbf{W} \mathbb{E}[\mathbf{z}] + \boldsymbol{\mu}</code></pre><p>Here, <span>$\mathbf{W}$</span> is the factor loadings or weight matrix.</p><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.predict-Union{Tuple{T}, Tuple{PPCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#StatsAPI.predict-Union{Tuple{T}, Tuple{PPCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>StatsAPI.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(M::PPCA, x)</code></pre><p>Transform observations <code>x</code> into latent variables. Here, <code>x</code> can be either a vector of length <code>d</code> or a matrix where each column is an observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L62-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{PPCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{PPCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>MultivariateStats.reconstruct</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reconstruct(M::PPCA, z)</code></pre><p>Approximately reconstruct observations from the latent variable given in <code>z</code>. Here, <code>z</code> can be either a vector of length <code>p</code> or a matrix where each column gives the latent variables for an observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L74-L80">source</a></section></article><p>Auxiliary functions:</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.ppcaml" href="#MultivariateStats.ppcaml"><code>MultivariateStats.ppcaml</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">ppcaml(Z, mean; ...)</code></pre><p>Compute probabilistic PCA using on maximum likelihood formulation for a centralized sample matrix <code>Z</code>.</p><p><em>Parameters</em>:</p><ul><li><code>Z</code>: a centralized samples matrix</li><li><code>mean</code>: The mean vector of the <strong>original</strong> samples, which can be a vector of</li></ul><p>length <code>d</code>, or an empty vector indicating a zero mean.</p><p>Returns the resultant <a href="#MultivariateStats.PPCA"><code>PPCA</code></a> model.</p><p><strong>Note:</strong> This function accepts two keyword arguments: <code>maxoutdim</code> and <code>tol</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L97-L111">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.ppcaem" href="#MultivariateStats.ppcaem"><code>MultivariateStats.ppcaem</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">ppcaem(S, mean, n; ...)</code></pre><p>Compute probabilistic PCA based on expectation-maximization algorithm for a given sample covariance matrix <code>S</code>.</p><p><em>Parameters</em>:</p><ul><li><code>S</code>: The sample covariance matrix.</li><li><code>mean</code>: The mean vector of original samples, which can be a vector of length <code>d</code>,</li></ul><p>or an empty vector indicating a zero mean.</p><ul><li><code>n</code>: The number of observations.</li></ul><p>Returns the resultant <a href="#MultivariateStats.PPCA"><code>PPCA</code></a> model.</p><p><strong>Note:</strong> This function accepts three keyword arguments: <code>maxoutdim</code>, <code>tol</code>, and <code>maxiter</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L143-L157">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.bayespca" href="#MultivariateStats.bayespca"><code>MultivariateStats.bayespca</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">bayespca(S, mean, n; ...)</code></pre><p>Compute probabilistic PCA using a Bayesian algorithm for a given sample covariance matrix <code>S</code>.</p><p><em>Parameters</em>:</p><ul><li><code>S</code>: The sample covariance matrix.</li><li><code>mean</code>: The mean vector of original samples, which can be a vector of length <code>d</code>,</li></ul><p>or an empty vector indicating a zero mean.</p><ul><li><code>n</code>: The number of observations.</li></ul><p>Returns the resultant <a href="#MultivariateStats.PPCA"><code>PPCA</code></a> model.</p><p><strong>Notes:</strong></p><ul><li>This function accepts three keyword arguments: <code>maxoutdim</code>, <code>tol</code>, and <code>maxiter</code>.</li><li>Function uses the <code>maxoutdim</code> parameter as an upper boundary when it automatically</li></ul><p>determines the latent space dimensionality.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/1863cd56fd6063687e550f2e81a6504583f03e8e/src/ppca.jl#L206-L223">source</a></section></article><hr/><h3 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h3><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Bishop, C. M. Pattern Recognition and Machine Learning, 2006.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../lda/">« Linear Discriminant Analysis</a><a class="docs-footer-nextpage" href="../ica/">Independent Component Analysis »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.14 on <span class="colophon-date" title="Thursday 3 March 2022 23:55">Thursday 3 March 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
