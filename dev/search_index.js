var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"Development","title":"API Reference","text":"","category":"section"},{"location":"api/#Current","page":"Development","title":"Current","text":"","category":"section"},{"location":"api/","page":"Development","title":"Development","text":"Table of the package models and corresponding function names used by these models.","category":"page"},{"location":"api/","page":"Development","title":"Development","text":"Function \\ Model CCA WHT ICA LDA FA PPCA PCA KPCA MDS\nfit x x x x x x x x x\ntransform x x x x x x x x x\npredict    x     \nindim  x x x x x x x x\noutdim x x x x x x x x x\nmean x x x x x x x ? \nvar     x x ? ? ?\ncov     x ?   \ncor x        \nprojection x    x x x x x\nreconstruct     x x x x \nloadings ?   ? x x ? ? ?\neigvals     ? ? ? ? x\neigvecs     ? ? ? ? ?\nlength         \nsize         ","category":"page"},{"location":"api/","page":"Development","title":"Development","text":"Note: ? refers to a possible implementation that is missing or called differently.","category":"page"},{"location":"api/#New","page":"Development","title":"New","text":"","category":"section"},{"location":"api/","page":"Development","title":"Development","text":"Function \\ Model WHT CCA LDA MC-LDA SS-LDA ICA FA PPCA PCA KPCA MDS\nfit x x x x x x x x x x x\ntransform x x  x x x x x x x x\npredict   x        \nindim -   x x x x x x x x\noutdim - x  x x x x x x x x\nmean x x  x x x x x x ? \nvar       x x ? ? ?\ncov       x ?   \ncor  x         \nprojection ? x     x x x x x\nreconstruct       x x x x \nloadings  ?     x x ? ? ?\neigvals       ? ? ? ? x\neigvecs       ? ? ? ? ?\nlength +  x        \nsize +          \n           ","category":"page"},{"location":"api/","page":"Development","title":"Development","text":"StatsBase.AbstractDataTransform\nWhitening\nInterface: fit, transfrom\nNew: length, mean, size\nStatsBase.RegressionModel\nLinearDiscriminant\nMethods:\nInterface: fit, predict, coef, dof, weights\nNew: evaluate, length\nMulticlassLDA\nMethods: fit, transfrom, indim, outdim, mean\nSubspaceLDA\nMethods: fit, transfrom, indim, outdim, mean\nCCA\nMethods: fit, transfrom, indim, outdim, mean\nSubtypes:\nAbstractDimensionalityReduction\nMethods: projection, var, reconstruct, loadings\nSubtypes:\nLinearDimensionalityReduction\nMethods: ICA, PCA\nNonlinearDimensionalityReduction\nMethods: KPCA, MDS\nLatentVariableModel or LatentVariableDimensionalityReduction\nMethods: FA, PPCA\nMethods: cov","category":"page"},{"location":"lda/#Linear-Discriminant-Analysis","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"","category":"section"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"Linear Discriminant Analysis (LDA) are statistical analysis methods to find a linear combination of features for separating observations in two classes.","category":"page"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"Note: Please refer to MulticlassLDA for methods that can discriminate between multiple classes.","category":"page"},{"location":"lda/#Overview-of-LDA","page":"Linear Discriminant Analysis","title":"Overview of LDA","text":"","category":"section"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"Suppose the samples in the positive and negative classes respectively with means: boldsymbolmu_p and boldsymbolmu_n, and covariances mathbfC_p and mathbfC_n. Then based on Fisher's Linear Discriminant Criteria, the optimal projection direction can be expressed as:","category":"page"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"    mathbfw = alpha cdot (mathbfC_p + mathbfC_n)^-1 (boldsymbolmu_p - boldsymbolmu_n)","category":"page"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"Here alpha is an arbitrary non-negative coefficient.","category":"page"},{"location":"lda/#Linear-Discriminant","page":"Linear Discriminant Analysis","title":"Linear Discriminant","text":"","category":"section"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"This package uses the LinearDiscriminant type to capture a linear discriminant functional:","category":"page"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"LinearDiscriminant","category":"page"},{"location":"lda/#MultivariateStats.LinearDiscriminant","page":"Linear Discriminant Analysis","title":"MultivariateStats.LinearDiscriminant","text":"A linear discriminant functional can be written as\n\n    f(mathbfx) = mathbfw^T mathbfx + b\n\nHere, w is the coefficient vector, and b is the bias constant.\n\n\n\n\n\n","category":"type"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"This type comes with several methods where f be an instance of  LinearDiscriminant.","category":"page"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"fit(::Type{LinearDiscriminant}, Xp::DenseMatrix{T}, Xn::DenseMatrix{T}; kwargs) where T<:Real\nevaluate(::LinearDiscriminant, ::AbstractVector)\nevaluate(::LinearDiscriminant, ::AbstractMatrix)\npredict(::LinearDiscriminant, ::AbstractVector)\npredict(::LinearDiscriminant, ::AbstractMatrix)\ncoef(::LinearDiscriminant)\ndof(::LinearDiscriminant)\nweights(::LinearDiscriminant)\nlength(::LinearDiscriminant)","category":"page"},{"location":"lda/#StatsBase.fit-Union{Tuple{T}, Tuple{Type{LinearDiscriminant}, DenseMatrix{T}, DenseMatrix{T}}} where T<:Real","page":"Linear Discriminant Analysis","title":"StatsBase.fit","text":"fit(LinearDiscriminant, Xp, Xn; covestimator = SimpleCovariance())\n\nPerforms LDA given both positive and negative samples. The function accepts follwing parameters:\n\nParameters\n\nXp: The sample matrix of the positive class.\nXn: The sample matrix of the negative class.\n\nKeyword arguments:\n\ncovestimator: Custom covariance estimator for between-class covariance. The covariance matrix will be calculated as cov(covestimator_between, #=data=#; dims=2, mean=zeros(#=...=#). Custom covariance estimators, available in other packages, may result in more robust discriminants for data with more features than observations.\n\n\n\n\n\n","category":"method"},{"location":"lda/#MultivariateStats.evaluate-Tuple{LinearDiscriminant, AbstractVector{T} where T}","page":"Linear Discriminant Analysis","title":"MultivariateStats.evaluate","text":"evaluate(f, x::AbstractVector)\n\nEvaluate the linear discriminant value, i.e wx + b, it returns a real value.\n\n\n\n\n\n","category":"method"},{"location":"lda/#MultivariateStats.evaluate-Tuple{LinearDiscriminant, AbstractMatrix{T} where T}","page":"Linear Discriminant Analysis","title":"MultivariateStats.evaluate","text":"evaluate(f, X::AbstractMatrix)\n\nEvaluate the linear discriminant value, i.e wx + b, for each sample in columns of X. The function returns a vector of length size(X, 2).\n\n\n\n\n\n","category":"method"},{"location":"lda/#StatsBase.predict-Tuple{LinearDiscriminant, AbstractVector{T} where T}","page":"Linear Discriminant Analysis","title":"StatsBase.predict","text":"predict(f, x::AbstractVector)\n\nMake prediction for the vector x. It returns true iff evaluate(f, x) is positive.\n\n\n\n\n\n","category":"method"},{"location":"lda/#StatsBase.predict-Tuple{LinearDiscriminant, AbstractMatrix{T} where T}","page":"Linear Discriminant Analysis","title":"StatsBase.predict","text":"predict(f, X::AbstractMatrix)\n\nMake predictions for the matrix X.\n\n\n\n\n\n","category":"method"},{"location":"lda/#StatsBase.coef-Tuple{LinearDiscriminant}","page":"Linear Discriminant Analysis","title":"StatsBase.coef","text":"coef(f::LinearDiscriminant)\n\nReturn the coefficients of the linear discriminant model.\n\n\n\n\n\n","category":"method"},{"location":"lda/#StatsBase.dof-Tuple{LinearDiscriminant}","page":"Linear Discriminant Analysis","title":"StatsBase.dof","text":"dof(f::LinearDiscriminant)\n\nReturn the number of degrees of freedom in the linear discriminant model.\n\n\n\n\n\n","category":"method"},{"location":"lda/#StatsBase.weights-Tuple{LinearDiscriminant}","page":"Linear Discriminant Analysis","title":"StatsBase.weights","text":"weights(f::LinearDiscriminant)\n\nReturn the linear discriminant model coefficient vector.\n\n\n\n\n\n","category":"method"},{"location":"lda/#Base.length-Tuple{LinearDiscriminant}","page":"Linear Discriminant Analysis","title":"Base.length","text":"Get the length of the coefficient vector.\n\n\n\n\n\n","category":"method"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"Additional functionality:","category":"page"},{"location":"lda/","page":"Linear Discriminant Analysis","title":"Linear Discriminant Analysis","text":"ldacov","category":"page"},{"location":"lda/#MultivariateStats.ldacov","page":"Linear Discriminant Analysis","title":"MultivariateStats.ldacov","text":"ldacov(C, μp, μn)\n\nPerforms LDA given a covariance matrix C and both mean vectors μp & μn.  Returns a linear discriminant functional of type LinearDiscriminant.\n\nParameters\n\nC: The pooled covariane matrix (i.e (Cp + Cn)2)\nμp: The mean vector of the positive class.\nμn: The mean vector of the negative class.\n\n\n\n\n\nldacov(Cp, Cn, μp, μn)\n\nPerforms LDA given covariances and mean vectors. Returns a linear discriminant functional of type LinearDiscriminant.\n\nParameters\n\nCp: The covariance matrix of the positive class.\nCn: The covariance matrix of the negative class.\nμp: The mean vector of the positive class.\nμn: The mean vector of the negative class.\n\nNote: The coefficient vector is scaled such that wμp + b = 1 and wμn + b = -1.\n\n\n\n\n\n","category":"function"},{"location":"whiten/#Data-Transformation","page":"Data Transformation","title":"Data Transformation","text":"","category":"section"},{"location":"whiten/#Whitening","page":"Data Transformation","title":"Whitening","text":"","category":"section"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"A whitening transformation is a decorrelation transformation that transforms a set of random variables into a set of new random variables with identity covariance (uncorrelated with unit variances).","category":"page"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"In particular, suppose a random vector has covariance mathbfC, then a whitening transform mathbfW is one that satisfy:","category":"page"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"   mathbfW^T mathbfC mathbfW = mathbfI","category":"page"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"Note that mathbfW is generally not unique. In particular, if mathbfW is a whitening transform, so is any of its rotation mathbfW mathbfR with mathbfR^T mathbfR = mathbfI.","category":"page"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"The package uses Whitening to represent a whitening transform.","category":"page"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"Whitening","category":"page"},{"location":"whiten/#MultivariateStats.Whitening","page":"Data Transformation","title":"MultivariateStats.Whitening","text":"A whitening transform representation.\n\n\n\n\n\n","category":"type"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"Whitening transformation can be fitted to data using the fit method.","category":"page"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"fit(::Type{Whitening}, X::AbstractMatrix{T}; kwargs...) where {T<:Real}\ntransform(::Whitening, ::AbstractVecOrMat)\nlength(::Whitening)\nmean(::Whitening)\nsize(::Whitening)","category":"page"},{"location":"whiten/#StatsBase.fit-Union{Tuple{T}, Tuple{Type{Whitening}, AbstractMatrix{T}}} where T<:Real","page":"Data Transformation","title":"StatsBase.fit","text":"fit(::Type{Whitening},  X::AbstractMatrix{T}; kwargs...)\n\nEstimate a whitening transform from the data given in X.\n\nThis function returns an instance of Whitening\n\nKeyword Arguments:\n\nregcoef: The regularization coefficient. The covariance will be regularized as follows when regcoef is positive C + (eigmax(C) * regcoef) * eye(d). Default values is zero(T).\ndims: if 1 the transformation calculated from the row samples. fit standardization parameters in column-wise fashion; if 2 the transformation calculated from the column samples. The default is nothing, which is equivalent to dims=2 with a deprecation warning.\nmean: The mean vector, which can be either of:\n0: the input data has already been centralized\nnothing: this function will compute the mean (default)\na pre-computed mean vector\n\nNote: This function internally relies on cov_whitening to derive the transformation W.\n\n\n\n\n\n","category":"method"},{"location":"whiten/#Base.length-Tuple{Whitening}","page":"Data Transformation","title":"Base.length","text":"length(f)\n\nGet the dimension of the  whitening transform f.\n\n\n\n\n\n","category":"method"},{"location":"whiten/#Statistics.mean-Tuple{Whitening}","page":"Data Transformation","title":"Statistics.mean","text":"mean(f)\n\nGet the mean vector of the whitening transformation f.\n\nNote: if mean is empty, this function returns a zero vector of length outdim .\n\n\n\n\n\n","category":"method"},{"location":"whiten/#Base.size-Tuple{Whitening}","page":"Data Transformation","title":"Base.size","text":"size(f)\n\nDimensions of the coefficient matrix of the whitening transform f.\n\n\n\n\n\n","category":"method"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"Additional methods","category":"page"},{"location":"whiten/","page":"Data Transformation","title":"Data Transformation","text":"cov_whitening\ncov_whitening!","category":"page"},{"location":"whiten/#MultivariateStats.cov_whitening","page":"Data Transformation","title":"MultivariateStats.cov_whitening","text":"cov_whitening(C)\n\nDerive the whitening transform coefficient matrix W given the covariance matrix C. Here, C can be either a square matrix, or an instance of Cholesky.\n\nInternally, this function solves the whitening transform using Cholesky factorization. The rationale is as follows: let mathbfC = mathbfU^T mathbfU and mathbfW = mathbfU^-1, then mathbfW^T mathbfC mathbfW = mathbfI.\n\nNote: The return matrix W is an upper triangular matrix.\n\n\n\n\n\ncov_whitening(C, regcoef)\n\nDerive a whitening transform based on a regularized covariance, as C + (eigmax(C) * regcoef) * eye(d).\n\n\n\n\n\n","category":"function"},{"location":"whiten/#MultivariateStats.cov_whitening!","page":"Data Transformation","title":"MultivariateStats.cov_whitening!","text":"cov_whitening!(C)\n\nIn-place version of cov_whitening(C), in which the input matrix C will be overwritten during computation. This can be more efficient when C is no longer used.\n\n\n\n\n\ncov_whitening!(C, regcoef)\n\nIn-place version of cov_whitening(C, regcoef), in which the input matrix C will be overwritten during computation. This can be more efficient when C is no longer used.\n\n\n\n\n\n","category":"function"},{"location":"#MultivariateStats.jl-Documentation","page":"Home","title":"MultivariateStats.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = MultivariateStats\nDocTestSetup = quote\n    using Statistics\n    using Random\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"MultivariateStats.jl is a Julia package for multivariate statistical analysis. It provides a rich set of useful analysis techniques, such as PCA, CCA, LDA, ICA, etc.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"whiten.md\", \"lda.md\", \"api.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"Notes: All methods implemented in this package adopt the column-major convention of JuliaStats: in a data matrix, each column corresponds to a sample/observation, while each row corresponds to a feature (variable or attribute).","category":"page"}]
}
