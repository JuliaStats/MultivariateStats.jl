<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Principal Component Analysis · MultivariateStats.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MultivariateStats.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../whiten/">Data Transformation</a></li><li><a class="tocitem" href="../lreg/">Regression</a></li><li><a class="tocitem" href="../lda/">Linear Discriminant Analysis</a></li><li class="is-active"><a class="tocitem" href>Principal Component Analysis</a><ul class="internal"><li><a class="tocitem" href="#Example"><span>Example</span></a></li><li><a class="tocitem" href="#Linear-Principal-Component-Analysis"><span>Linear Principal Component Analysis</span></a></li><li><a class="tocitem" href="#Kernel-Principal-Component-Analysis"><span>Kernel Principal Component Analysis</span></a></li><li><a class="tocitem" href="#Probabilistic-Principal-Component-Analysis"><span>Probabilistic Principal Component Analysis</span></a></li></ul></li><li><a class="tocitem" href="../ica/">Independent Component Analysis</a></li><li><a class="tocitem" href="../cca/">Canonical Correlation Analysis</a></li><li><a class="tocitem" href="../fa/">Factor Analysis</a></li><li><a class="tocitem" href="../mds/">Multidimensional Scaling</a></li><li><a class="tocitem" href="../api/">Development</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Principal Component Analysis</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Principal Component Analysis</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/master/docs/src/pca.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Principal-Component-Analysis"><a class="docs-heading-anchor" href="#Principal-Component-Analysis">Principal Component Analysis</a><a id="Principal-Component-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Principal-Component-Analysis" title="Permalink"></a></h1><p><a href="http://en.wikipedia.org/wiki/Principal_component_analysis">Principal Component Analysis</a> (PCA) derives an orthogonal projection to convert a given set of observations to linearly uncorrelated variables, called <em>principal components</em>.</p><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><p>Performing <a href="#MultivariateStats.PCA"><code>PCA</code></a> on <em>Iris</em> data set:</p><pre><code class="language-julia hljs">using MultivariateStats, RDatasets, Plots

# load iris dataset
iris = dataset(&quot;datasets&quot;, &quot;iris&quot;)

# split half to training set
Xtr = Matrix(iris[1:2:end,1:4])&#39;
Xtr_labels = Vector(iris[1:2:end,5])

# split other half to testing set
Xte = Matrix(iris[2:2:end,1:4])&#39;
Xte_labels = Vector(iris[2:2:end,5])</code></pre><p>Suppose <code>Xtr</code> and <code>Xte</code> are training and testing data matrix, with each observation in a column. We train a PCA model, allowing up to 3 dimensions:</p><pre><code class="language-julia hljs">M = fit(PCA, Xtr; maxoutdim=3)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PCA(indim = 4, outdim = 3, principalratio = 0.9957325846529409)

Pattern matrix (unstandardized loadings):
────────────────────────────────────
         PC1         PC2         PC3
────────────────────────────────────
1   0.70954    0.344711   -0.160106
2  -0.227592   0.29865     0.215417
3   1.77976   -0.0797511   0.0197705
4   0.764206  -0.0453779   0.166764
────────────────────────────────────

Importance of components:
─────────────────────────────────────────────────────────
                                PC1        PC2        PC3
─────────────────────────────────────────────────────────
SS Loadings (Eigenvalues)  4.3068    0.216437   0.100239
Variance explained         0.927532  0.0466128  0.021588
Cumulative variance        0.927532  0.974145   0.995733
Proportion explained       0.931507  0.0468125  0.0216805
Cumulative proportion      0.931507  0.978319   1.0
─────────────────────────────────────────────────────────</code></pre><p>Then, apply PCA model to the testing set</p><pre><code class="language-julia hljs">Yte = predict(M, Xte)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×75 Matrix{Float64}:
  2.72714    2.75491     2.32396   …  -1.92047   -1.74161   -1.37706
 -0.230916  -0.406149    0.646374      0.246554   0.127625  -0.280295
  0.253119   0.0271266  -0.230469     -0.180044  -0.123165  -0.314992</code></pre><p>And, reconstruct testing observations (approximately) to the original space</p><pre><code class="language-julia hljs">Xr = reconstruct(M, Yte)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×75 Matrix{Float64}:
 4.86449  4.61087   5.40782   5.00775   …  6.79346  6.58825  6.46774  5.94384
 3.04262  3.08695   3.89061   3.39069      3.20785  3.13416  3.03873  2.94737
 1.46099  1.48132   1.68656   1.48668      5.91124  5.39197  5.25542  5.02469
 0.10362  0.229519  0.421233  0.221041     2.28224  1.99665  1.91243  1.91901</code></pre><p>Now, we group results by testing set labels for color coding and visualize first 3 principal components in 3D plot</p><pre><code class="language-julia hljs">setosa = Yte[:,Xte_labels.==&quot;setosa&quot;]
versicolor = Yte[:,Xte_labels.==&quot;versicolor&quot;]
virginica = Yte[:,Xte_labels.==&quot;virginica&quot;]

p = scatter(setosa[1,:],setosa[2,:],setosa[3,:],marker=:circle,linewidth=0)
scatter!(versicolor[1,:],versicolor[2,:],versicolor[3,:],marker=:circle,linewidth=0)
scatter!(virginica[1,:],virginica[2,:],virginica[3,:],marker=:circle,linewidth=0)
plot!(p,xlabel=&quot;PC1&quot;,ylabel=&quot;PC2&quot;,zlabel=&quot;PC3&quot;)</code></pre><?xml version="1.0" encoding="utf-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600">
<defs>
  <clipPath id="clip600">
    <rect x="0" y="0" width="2400" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip600)" d="M0 1600 L2400 1600 L2400 0 L0 0  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip601">
    <rect x="480" y="0" width="1681" height="1600"/>
  </clipPath>
</defs>
<defs>
  <clipPath id="clip602">
    <rect x="287" y="47" width="2066" height="1377"/>
  </clipPath>
</defs>
<path clip-path="url(#clip602)" d="M1195.11 1168.56 L1195.11 647.805 L1307.79 387.426 L1502.97 537.756 L1502.97 1058.51 L1390.29 1318.89 L1195.11 1168.56  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="838.346,1169.46 1235.54,825.476 1235.54,137.508 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="935.936,1197.63 1333.13,853.647 1333.13,165.679 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1033.53,1225.8 1430.72,881.819 1430.72,193.851 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1131.11,1253.97 1528.31,909.99 1528.31,222.023 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1228.7,1282.15 1625.9,938.162 1625.9,250.194 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1326.29,1310.32 1723.49,966.334 1723.49,278.366 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1423.88,1338.49 1821.08,994.505 1821.08,306.537 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="777.478,1151.89 1465.45,1350.49 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="838.346,1169.46 843.113,1165.33 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="935.936,1197.63 940.702,1193.5 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1033.53,1225.8 1038.29,1221.67 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1131.11,1253.97 1135.88,1249.85 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1228.7,1282.15 1233.47,1278.02 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1326.29,1310.32 1331.06,1306.19 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1423.88,1338.49 1428.65,1334.36 "/>
<path clip-path="url(#clip600)" d="M759.708 1192.73 L789.384 1192.73 L789.384 1196.66 L759.708 1196.66 L759.708 1192.73 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M813.643 1190.92 Q816.999 1191.64 818.874 1193.91 Q820.773 1196.18 820.773 1199.51 Q820.773 1204.63 817.254 1207.43 Q813.736 1210.23 807.254 1210.23 Q805.078 1210.23 802.763 1209.79 Q800.472 1209.37 798.018 1208.51 L798.018 1204 Q799.963 1205.13 802.277 1205.71 Q804.592 1206.29 807.115 1206.29 Q811.513 1206.29 813.805 1204.56 Q816.12 1202.82 816.12 1199.51 Q816.12 1196.45 813.967 1194.74 Q811.837 1193.01 808.018 1193.01 L803.99 1193.01 L803.99 1189.16 L808.203 1189.16 Q811.652 1189.16 813.481 1187.8 Q815.31 1186.41 815.31 1183.82 Q815.31 1181.15 813.412 1179.74 Q811.537 1178.31 808.018 1178.31 Q806.097 1178.31 803.898 1178.72 Q801.699 1179.14 799.06 1180.02 L799.06 1175.85 Q801.722 1175.11 804.037 1174.74 Q806.375 1174.37 808.435 1174.37 Q813.759 1174.37 816.861 1176.8 Q819.962 1179.21 819.962 1183.33 Q819.962 1186.2 818.319 1188.19 Q816.675 1190.16 813.643 1190.92 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M858.247 1220.9 L887.922 1220.9 L887.922 1224.83 L858.247 1224.83 L858.247 1220.9 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M902.043 1233.79 L918.362 1233.79 L918.362 1237.73 L896.418 1237.73 L896.418 1233.79 Q899.08 1231.04 903.663 1226.41 Q908.269 1221.76 909.45 1220.41 Q911.695 1217.89 912.575 1216.15 Q913.478 1214.39 913.478 1212.7 Q913.478 1209.95 911.533 1208.21 Q909.612 1206.48 906.51 1206.48 Q904.311 1206.48 901.857 1207.24 Q899.427 1208.01 896.649 1209.56 L896.649 1204.83 Q899.473 1203.7 901.927 1203.12 Q904.381 1202.54 906.418 1202.54 Q911.788 1202.54 914.982 1205.23 Q918.177 1207.91 918.177 1212.4 Q918.177 1214.53 917.367 1216.45 Q916.58 1218.35 914.473 1220.95 Q913.894 1221.62 910.793 1224.83 Q907.691 1228.03 902.043 1233.79 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M955.465 1249.07 L985.141 1249.07 L985.141 1253.01 L955.465 1253.01 L955.465 1249.07 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M996.044 1261.96 L1003.68 1261.96 L1003.68 1235.6 L995.373 1237.27 L995.373 1233.01 L1003.64 1231.34 L1008.31 1231.34 L1008.31 1261.96 L1015.95 1261.96 L1015.95 1265.9 L996.044 1265.9 L996.044 1261.96 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1101.6 1262.59 Q1097.99 1262.59 1096.16 1266.15 Q1094.35 1269.7 1094.35 1276.83 Q1094.35 1283.93 1096.16 1287.5 Q1097.99 1291.04 1101.6 1291.04 Q1105.23 1291.04 1107.04 1287.5 Q1108.86 1283.93 1108.86 1276.83 Q1108.86 1269.7 1107.04 1266.15 Q1105.23 1262.59 1101.6 1262.59 M1101.6 1258.89 Q1107.41 1258.89 1110.46 1263.49 Q1113.54 1268.08 1113.54 1276.83 Q1113.54 1285.55 1110.46 1290.16 Q1107.41 1294.74 1101.6 1294.74 Q1095.79 1294.74 1092.71 1290.16 Q1089.65 1285.55 1089.65 1276.83 Q1089.65 1268.08 1092.71 1263.49 Q1095.79 1258.89 1101.6 1258.89 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1191.22 1318.31 L1198.86 1318.31 L1198.86 1291.94 L1190.55 1293.61 L1190.55 1289.35 L1198.82 1287.68 L1203.49 1287.68 L1203.49 1318.31 L1211.13 1318.31 L1211.13 1322.24 L1191.22 1322.24 L1191.22 1318.31 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1292.4 1346.48 L1308.72 1346.48 L1308.72 1350.41 L1286.77 1350.41 L1286.77 1346.48 Q1289.44 1343.72 1294.02 1339.09 Q1298.63 1334.44 1299.81 1333.1 Q1302.05 1330.58 1302.93 1328.84 Q1303.84 1327.08 1303.84 1325.39 Q1303.84 1322.64 1301.89 1320.9 Q1299.97 1319.16 1296.87 1319.16 Q1294.67 1319.16 1292.21 1319.93 Q1289.78 1320.69 1287.01 1322.24 L1287.01 1317.52 Q1289.83 1316.39 1292.28 1315.81 Q1294.74 1315.23 1296.77 1315.23 Q1302.15 1315.23 1305.34 1317.91 Q1308.53 1320.6 1308.53 1325.09 Q1308.53 1327.22 1307.72 1329.14 Q1306.94 1331.04 1304.83 1333.63 Q1304.25 1334.3 1301.15 1337.52 Q1298.05 1340.72 1292.4 1346.48 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1399.18 1359.95 Q1402.54 1360.67 1404.41 1362.94 Q1406.31 1365.21 1406.31 1368.54 Q1406.31 1373.66 1402.79 1376.46 Q1399.27 1379.26 1392.79 1379.26 Q1390.61 1379.26 1388.3 1378.82 Q1386.01 1378.4 1383.55 1377.54 L1383.55 1373.03 Q1385.5 1374.16 1387.81 1374.74 Q1390.13 1375.32 1392.65 1375.32 Q1397.05 1375.32 1399.34 1373.59 Q1401.66 1371.85 1401.66 1368.54 Q1401.66 1365.48 1399.5 1363.77 Q1397.37 1362.04 1393.55 1362.04 L1389.53 1362.04 L1389.53 1358.19 L1393.74 1358.19 Q1397.19 1358.19 1399.02 1356.83 Q1400.85 1355.44 1400.85 1352.85 Q1400.85 1350.18 1398.95 1348.77 Q1397.07 1347.34 1393.55 1347.34 Q1391.63 1347.34 1389.43 1347.75 Q1387.23 1348.17 1384.6 1349.05 L1384.6 1344.88 Q1387.26 1344.14 1389.57 1343.77 Q1391.91 1343.4 1393.97 1343.4 Q1399.29 1343.4 1402.4 1345.83 Q1405.5 1348.24 1405.5 1352.36 Q1405.5 1355.23 1403.85 1357.22 Q1402.21 1359.19 1399.18 1359.95 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M947.83 1389.1 L947.83 1406.95 L955.914 1406.95 Q960.402 1406.95 962.853 1404.63 Q965.304 1402.3 965.304 1398.01 Q965.304 1393.74 962.853 1391.42 Q960.402 1389.1 955.914 1389.1 L947.83 1389.1 M941.4 1383.81 L955.914 1383.81 Q963.903 1383.81 967.977 1387.44 Q972.083 1391.04 972.083 1398.01 Q972.083 1405.04 967.977 1408.64 Q963.903 1412.23 955.914 1412.23 L947.83 1412.23 L947.83 1431.33 L941.4 1431.33 L941.4 1383.81 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1016.29 1387.47 L1016.29 1394.25 Q1013.05 1391.23 1009.35 1389.73 Q1005.69 1388.24 1001.56 1388.24 Q993.408 1388.24 989.08 1393.23 Q984.751 1398.2 984.751 1407.62 Q984.751 1417.01 989.08 1422.01 Q993.408 1426.97 1001.56 1426.97 Q1005.69 1426.97 1009.35 1425.48 Q1013.05 1423.98 1016.29 1420.96 L1016.29 1427.67 Q1012.92 1429.96 1009.13 1431.11 Q1005.38 1432.25 1001.17 1432.25 Q990.385 1432.25 984.178 1425.67 Q977.971 1419.05 977.971 1407.62 Q977.971 1396.16 984.178 1389.57 Q990.385 1382.95 1001.17 1382.95 Q1005.44 1382.95 1009.2 1384.1 Q1012.98 1385.21 1016.29 1387.47 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1027.91 1425.92 L1038.41 1425.92 L1038.41 1389.67 L1026.99 1391.96 L1026.99 1386.1 L1038.35 1383.81 L1044.78 1383.81 L1044.78 1425.92 L1055.28 1425.92 L1055.28 1431.33 L1027.91 1431.33 L1027.91 1425.92 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1479.67,1338.17 791.698,1139.57 791.698,451.605 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1554.83,1273.08 866.863,1074.48 866.863,386.51 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1630,1207.98 942.028,1009.38 942.028,321.415 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1705.16,1142.89 1017.19,944.288 1017.19,256.321 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1780.33,1077.79 1092.36,879.194 1092.36,191.226 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1855.49,1012.7 1167.52,814.099 1167.52,126.131 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1465.45,1350.49 1862.64,1006.5 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1479.67,1338.17 1471.41,1335.79 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1554.83,1273.08 1546.58,1270.69 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1630,1207.98 1621.74,1205.6 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1705.16,1142.89 1696.91,1140.5 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1780.33,1077.79 1772.07,1075.41 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1855.49,1012.7 1847.24,1010.31 "/>
<path clip-path="url(#clip600)" d="M1506.1 1350.06 L1535.77 1350.06 L1535.77 1354 L1506.1 1354 L1506.1 1350.06 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1546.68 1362.96 L1554.31 1362.96 L1554.31 1336.59 L1546 1338.26 L1546 1334 L1554.27 1332.33 L1558.94 1332.33 L1558.94 1362.96 L1566.58 1362.96 L1566.58 1366.89 L1546.68 1366.89 L1546.68 1362.96 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1576.03 1361.01 L1580.91 1361.01 L1580.91 1366.89 L1576.03 1366.89 L1576.03 1361.01 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1601.1 1335.41 Q1597.49 1335.41 1595.66 1338.97 Q1593.85 1342.52 1593.85 1349.65 Q1593.85 1356.75 1595.66 1360.32 Q1597.49 1363.86 1601.1 1363.86 Q1604.73 1363.86 1606.54 1360.32 Q1608.37 1356.75 1608.37 1349.65 Q1608.37 1342.52 1606.54 1338.97 Q1604.73 1335.41 1601.1 1335.41 M1601.1 1331.71 Q1606.91 1331.71 1609.96 1336.31 Q1613.04 1340.9 1613.04 1349.65 Q1613.04 1358.37 1609.96 1362.98 Q1606.91 1367.56 1601.1 1367.56 Q1595.29 1367.56 1592.21 1362.98 Q1589.15 1358.37 1589.15 1349.65 Q1589.15 1340.9 1592.21 1336.31 Q1595.29 1331.71 1601.1 1331.71 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1581.26 1284.97 L1610.94 1284.97 L1610.94 1288.9 L1581.26 1288.9 L1581.26 1284.97 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1631.03 1270.31 Q1627.42 1270.31 1625.59 1273.88 Q1623.79 1277.42 1623.79 1284.55 Q1623.79 1291.66 1625.59 1295.22 Q1627.42 1298.76 1631.03 1298.76 Q1634.66 1298.76 1636.47 1295.22 Q1638.3 1291.66 1638.3 1284.55 Q1638.3 1277.42 1636.47 1273.88 Q1634.66 1270.31 1631.03 1270.31 M1631.03 1266.61 Q1636.84 1266.61 1639.9 1271.22 Q1642.97 1275.8 1642.97 1284.55 Q1642.97 1293.28 1639.9 1297.88 Q1636.84 1302.47 1631.03 1302.47 Q1625.22 1302.47 1622.14 1297.88 Q1619.09 1293.28 1619.09 1284.55 Q1619.09 1275.8 1622.14 1271.22 Q1625.22 1266.61 1631.03 1266.61 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1651.19 1295.92 L1656.08 1295.92 L1656.08 1301.8 L1651.19 1301.8 L1651.19 1295.92 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1666.31 1267.24 L1684.66 1267.24 L1684.66 1271.17 L1670.59 1271.17 L1670.59 1279.64 Q1671.61 1279.3 1672.63 1279.13 Q1673.65 1278.95 1674.66 1278.95 Q1680.45 1278.95 1683.83 1282.12 Q1687.21 1285.29 1687.21 1290.71 Q1687.21 1296.29 1683.74 1299.39 Q1680.27 1302.47 1673.95 1302.47 Q1671.77 1302.47 1669.5 1302.1 Q1667.26 1301.73 1664.85 1300.99 L1664.85 1296.29 Q1666.93 1297.42 1669.16 1297.98 Q1671.38 1298.53 1673.85 1298.53 Q1677.86 1298.53 1680.2 1296.43 Q1682.53 1294.32 1682.53 1290.71 Q1682.53 1287.1 1680.2 1284.99 Q1677.86 1282.88 1673.85 1282.88 Q1671.98 1282.88 1670.1 1283.3 Q1668.25 1283.72 1666.31 1284.6 L1666.31 1267.24 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1668.37 1205.22 Q1664.76 1205.22 1662.93 1208.78 Q1661.13 1212.33 1661.13 1219.46 Q1661.13 1226.56 1662.93 1230.13 Q1664.76 1233.67 1668.37 1233.67 Q1672.01 1233.67 1673.81 1230.13 Q1675.64 1226.56 1675.64 1219.46 Q1675.64 1212.33 1673.81 1208.78 Q1672.01 1205.22 1668.37 1205.22 M1668.37 1201.52 Q1674.18 1201.52 1677.24 1206.12 Q1680.32 1210.71 1680.32 1219.46 Q1680.32 1228.18 1677.24 1232.79 Q1674.18 1237.37 1668.37 1237.37 Q1662.56 1237.37 1659.48 1232.79 Q1656.43 1228.18 1656.43 1219.46 Q1656.43 1210.71 1659.48 1206.12 Q1662.56 1201.52 1668.37 1201.52 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1688.53 1230.82 L1693.42 1230.82 L1693.42 1236.7 L1688.53 1236.7 L1688.53 1230.82 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1713.6 1205.22 Q1709.99 1205.22 1708.16 1208.78 Q1706.36 1212.33 1706.36 1219.46 Q1706.36 1226.56 1708.16 1230.13 Q1709.99 1233.67 1713.6 1233.67 Q1717.24 1233.67 1719.04 1230.13 Q1720.87 1226.56 1720.87 1219.46 Q1720.87 1212.33 1719.04 1208.78 Q1717.24 1205.22 1713.6 1205.22 M1713.6 1201.52 Q1719.41 1201.52 1722.47 1206.12 Q1725.55 1210.71 1725.55 1219.46 Q1725.55 1228.18 1722.47 1232.79 Q1719.41 1237.37 1713.6 1237.37 Q1707.79 1237.37 1704.71 1232.79 Q1701.66 1228.18 1701.66 1219.46 Q1701.66 1210.71 1704.71 1206.12 Q1707.79 1201.52 1713.6 1201.52 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1743.54 1140.13 Q1739.93 1140.13 1738.1 1143.69 Q1736.29 1147.23 1736.29 1154.36 Q1736.29 1161.47 1738.1 1165.03 Q1739.93 1168.57 1743.54 1168.57 Q1747.17 1168.57 1748.98 1165.03 Q1750.81 1161.47 1750.81 1154.36 Q1750.81 1147.23 1748.98 1143.69 Q1747.17 1140.13 1743.54 1140.13 M1743.54 1136.42 Q1749.35 1136.42 1752.4 1141.03 Q1755.48 1145.61 1755.48 1154.36 Q1755.48 1163.09 1752.4 1167.69 Q1749.35 1172.28 1743.54 1172.28 Q1737.73 1172.28 1734.65 1167.69 Q1731.59 1163.09 1731.59 1154.36 Q1731.59 1145.61 1734.65 1141.03 Q1737.73 1136.42 1743.54 1136.42 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1763.7 1165.73 L1768.58 1165.73 L1768.58 1171.61 L1763.7 1171.61 L1763.7 1165.73 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1778.81 1137.05 L1797.17 1137.05 L1797.17 1140.98 L1783.1 1140.98 L1783.1 1149.45 Q1784.12 1149.11 1785.13 1148.94 Q1786.15 1148.76 1787.17 1148.76 Q1792.96 1148.76 1796.34 1151.93 Q1799.72 1155.1 1799.72 1160.52 Q1799.72 1166.1 1796.24 1169.2 Q1792.77 1172.28 1786.45 1172.28 Q1784.28 1172.28 1782.01 1171.91 Q1779.76 1171.54 1777.36 1170.8 L1777.36 1166.1 Q1779.44 1167.23 1781.66 1167.79 Q1783.88 1168.34 1786.36 1168.34 Q1790.36 1168.34 1792.7 1166.24 Q1795.04 1164.13 1795.04 1160.52 Q1795.04 1156.91 1792.7 1154.8 Q1790.36 1152.69 1786.36 1152.69 Q1784.49 1152.69 1782.61 1153.11 Q1780.76 1153.53 1778.81 1154.41 L1778.81 1137.05 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1807.43 1102.58 L1815.07 1102.58 L1815.07 1076.21 L1806.76 1077.88 L1806.76 1073.62 L1815.02 1071.95 L1819.7 1071.95 L1819.7 1102.58 L1827.34 1102.58 L1827.34 1106.51 L1807.43 1106.51 L1807.43 1102.58 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1836.78 1100.63 L1841.66 1100.63 L1841.66 1106.51 L1836.78 1106.51 L1836.78 1100.63 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1861.85 1075.03 Q1858.24 1075.03 1856.41 1078.6 Q1854.6 1082.14 1854.6 1089.27 Q1854.6 1096.37 1856.41 1099.94 Q1858.24 1103.48 1861.85 1103.48 Q1865.48 1103.48 1867.29 1099.94 Q1869.12 1096.37 1869.12 1089.27 Q1869.12 1082.14 1867.29 1078.6 Q1865.48 1075.03 1861.85 1075.03 M1861.85 1071.33 Q1867.66 1071.33 1870.72 1075.93 Q1873.79 1080.52 1873.79 1089.27 Q1873.79 1097.99 1870.72 1102.6 Q1867.66 1107.18 1861.85 1107.18 Q1856.04 1107.18 1852.96 1102.6 Q1849.91 1097.99 1849.91 1089.27 Q1849.91 1080.52 1852.96 1075.93 Q1856.04 1071.33 1861.85 1071.33 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1882.59 1037.48 L1890.23 1037.48 L1890.23 1011.12 L1881.92 1012.78 L1881.92 1008.52 L1890.19 1006.86 L1894.86 1006.86 L1894.86 1037.48 L1902.5 1037.48 L1902.5 1041.42 L1882.59 1041.42 L1882.59 1037.48 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1911.95 1035.54 L1916.83 1035.54 L1916.83 1041.42 L1911.95 1041.42 L1911.95 1035.54 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1927.06 1006.86 L1945.42 1006.86 L1945.42 1010.79 L1931.34 1010.79 L1931.34 1019.26 Q1932.36 1018.92 1933.38 1018.76 Q1934.4 1018.57 1935.42 1018.57 Q1941.2 1018.57 1944.58 1021.74 Q1947.96 1024.91 1947.96 1030.33 Q1947.96 1035.91 1944.49 1039.01 Q1941.02 1042.09 1934.7 1042.09 Q1932.52 1042.09 1930.26 1041.72 Q1928.01 1041.35 1925.6 1040.61 L1925.6 1035.91 Q1927.69 1037.04 1929.91 1037.6 Q1932.13 1038.15 1934.61 1038.15 Q1938.61 1038.15 1940.95 1036.05 Q1943.29 1033.94 1943.29 1030.33 Q1943.29 1026.72 1940.95 1024.61 Q1938.61 1022.5 1934.61 1022.5 Q1932.73 1022.5 1930.86 1022.92 Q1929.01 1023.34 1927.06 1024.22 L1927.06 1006.86 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1736.91 1316.4 L1736.91 1334.26 L1744.99 1334.26 Q1749.48 1334.26 1751.93 1331.94 Q1754.38 1329.61 1754.38 1325.32 Q1754.38 1321.05 1751.93 1318.73 Q1749.48 1316.4 1744.99 1316.4 L1736.91 1316.4 M1730.48 1311.12 L1744.99 1311.12 Q1752.98 1311.12 1757.06 1314.75 Q1761.16 1318.34 1761.16 1325.32 Q1761.16 1332.35 1757.06 1335.95 Q1752.98 1339.54 1744.99 1339.54 L1736.91 1339.54 L1736.91 1358.64 L1730.48 1358.64 L1730.48 1311.12 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1805.37 1314.78 L1805.37 1321.56 Q1802.12 1318.54 1798.43 1317.04 Q1794.77 1315.54 1790.63 1315.54 Q1782.49 1315.54 1778.16 1320.54 Q1773.83 1325.51 1773.83 1334.93 Q1773.83 1344.32 1778.16 1349.31 Q1782.49 1354.28 1790.63 1354.28 Q1794.77 1354.28 1798.43 1352.78 Q1802.12 1351.29 1805.37 1348.26 L1805.37 1354.98 Q1802 1357.27 1798.21 1358.42 Q1794.45 1359.56 1790.25 1359.56 Q1779.46 1359.56 1773.26 1352.97 Q1767.05 1346.35 1767.05 1334.93 Q1767.05 1323.47 1773.26 1316.88 Q1779.46 1310.26 1790.25 1310.26 Q1794.52 1310.26 1798.27 1311.41 Q1802.06 1312.52 1805.37 1314.78 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M1821.41 1353.23 L1843.85 1353.23 L1843.85 1358.64 L1813.68 1358.64 L1813.68 1353.23 Q1817.34 1349.44 1823.64 1343.08 Q1829.97 1336.68 1831.6 1334.83 Q1834.68 1331.36 1835.89 1328.98 Q1837.14 1326.56 1837.14 1324.23 Q1837.14 1320.45 1834.46 1318.06 Q1831.82 1315.67 1827.56 1315.67 Q1824.53 1315.67 1821.16 1316.72 Q1817.82 1317.77 1814 1319.9 L1814 1313.41 Q1817.88 1311.85 1821.25 1311.06 Q1824.63 1310.26 1827.43 1310.26 Q1834.81 1310.26 1839.2 1313.95 Q1843.6 1317.64 1843.6 1323.82 Q1843.6 1326.75 1842.48 1329.39 Q1841.4 1332 1838.5 1335.56 Q1837.71 1336.49 1833.44 1340.91 Q1829.18 1345.3 1821.41 1353.23 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="777.478,1134.1 1174.68,790.113 1862.64,988.712 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="777.478,995.132 1174.68,651.148 1862.64,849.748 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="777.478,856.168 1174.68,512.184 1862.64,710.783 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="777.478,717.204 1174.68,373.22 1862.64,571.819 "/>
<polyline clip-path="url(#clip602)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="777.478,578.24 1174.68,234.256 1862.64,432.855 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="777.478,1151.89 777.478,463.92 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="777.478,1134.1 782.244,1129.97 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="777.478,995.132 782.244,991.004 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="777.478,856.168 782.244,852.04 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="777.478,717.204 782.244,713.076 "/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="777.478,578.24 782.244,574.112 "/>
<path clip-path="url(#clip600)" d="M611.572 1134.55 L641.248 1134.55 L641.248 1138.48 L611.572 1138.48 L611.572 1134.55 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M661.34 1119.9 Q657.729 1119.9 655.9 1123.46 Q654.095 1127 654.095 1134.13 Q654.095 1141.24 655.9 1144.8 Q657.729 1148.34 661.34 1148.34 Q664.974 1148.34 666.78 1144.8 Q668.609 1141.24 668.609 1134.13 Q668.609 1127 666.78 1123.46 Q664.974 1119.9 661.34 1119.9 M661.34 1116.19 Q667.15 1116.19 670.206 1120.8 Q673.285 1125.38 673.285 1134.13 Q673.285 1142.86 670.206 1147.46 Q667.15 1152.05 661.34 1152.05 Q655.53 1152.05 652.451 1147.46 Q649.396 1142.86 649.396 1134.13 Q649.396 1125.38 652.451 1120.8 Q655.53 1116.19 661.34 1116.19 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M681.502 1145.5 L686.386 1145.5 L686.386 1151.38 L681.502 1151.38 L681.502 1145.5 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M696.618 1116.82 L714.974 1116.82 L714.974 1120.75 L700.9 1120.75 L700.9 1129.22 Q701.919 1128.88 702.937 1128.71 Q703.956 1128.53 704.974 1128.53 Q710.761 1128.53 714.141 1131.7 Q717.521 1134.87 717.521 1140.29 Q717.521 1145.87 714.048 1148.97 Q710.576 1152.05 704.257 1152.05 Q702.081 1152.05 699.812 1151.68 Q697.567 1151.31 695.16 1150.57 L695.16 1145.87 Q697.243 1147 699.465 1147.56 Q701.687 1148.11 704.164 1148.11 Q708.169 1148.11 710.507 1146.01 Q712.845 1143.9 712.845 1140.29 Q712.845 1136.68 710.507 1134.57 Q708.169 1132.46 704.164 1132.46 Q702.289 1132.46 700.414 1132.88 Q698.562 1133.3 696.618 1134.18 L696.618 1116.82 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M736.733 1119.9 Q733.122 1119.9 731.294 1123.46 Q729.488 1127 729.488 1134.13 Q729.488 1141.24 731.294 1144.8 Q733.122 1148.34 736.733 1148.34 Q740.368 1148.34 742.173 1144.8 Q744.002 1141.24 744.002 1134.13 Q744.002 1127 742.173 1123.46 Q740.368 1119.9 736.733 1119.9 M736.733 1116.19 Q742.544 1116.19 745.599 1120.8 Q748.678 1125.38 748.678 1134.13 Q748.678 1142.86 745.599 1147.46 Q742.544 1152.05 736.733 1152.05 Q730.923 1152.05 727.845 1147.46 Q724.789 1142.86 724.789 1134.13 Q724.789 1125.38 727.845 1120.8 Q730.923 1116.19 736.733 1116.19 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M612.567 995.584 L642.243 995.584 L642.243 999.519 L612.567 999.519 L612.567 995.584 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M662.336 980.931 Q658.725 980.931 656.896 984.496 Q655.09 988.037 655.09 995.167 Q655.09 1002.27 656.896 1005.84 Q658.725 1009.38 662.336 1009.38 Q665.97 1009.38 667.775 1005.84 Q669.604 1002.27 669.604 995.167 Q669.604 988.037 667.775 984.496 Q665.97 980.931 662.336 980.931 M662.336 977.227 Q668.146 977.227 671.201 981.834 Q674.28 986.417 674.28 995.167 Q674.28 1003.89 671.201 1008.5 Q668.146 1013.08 662.336 1013.08 Q656.525 1013.08 653.447 1008.5 Q650.391 1003.89 650.391 995.167 Q650.391 986.417 653.447 981.834 Q656.525 977.227 662.336 977.227 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M682.498 1006.53 L687.382 1006.53 L687.382 1012.41 L682.498 1012.41 L682.498 1006.53 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M701.595 1008.48 L717.914 1008.48 L717.914 1012.41 L695.97 1012.41 L695.97 1008.48 Q698.632 1005.72 703.215 1001.09 Q707.821 996.44 709.002 995.098 Q711.247 992.574 712.127 990.838 Q713.03 989.079 713.03 987.389 Q713.03 984.635 711.085 982.899 Q709.164 981.162 706.062 981.162 Q703.863 981.162 701.409 981.926 Q698.979 982.69 696.201 984.241 L696.201 979.519 Q699.025 978.385 701.479 977.806 Q703.933 977.227 705.97 977.227 Q711.34 977.227 714.534 979.912 Q717.729 982.598 717.729 987.088 Q717.729 989.218 716.919 991.139 Q716.132 993.037 714.025 995.63 Q713.446 996.301 710.345 999.519 Q707.243 1002.71 701.595 1008.48 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M727.775 977.852 L746.131 977.852 L746.131 981.787 L732.057 981.787 L732.057 990.26 Q733.076 989.912 734.094 989.75 Q735.113 989.565 736.132 989.565 Q741.919 989.565 745.298 992.736 Q748.678 995.908 748.678 1001.32 Q748.678 1006.9 745.206 1010 Q741.733 1013.08 735.414 1013.08 Q733.238 1013.08 730.97 1012.71 Q728.724 1012.34 726.317 1011.6 L726.317 1006.9 Q728.4 1008.04 730.622 1008.59 Q732.845 1009.15 735.321 1009.15 Q739.326 1009.15 741.664 1007.04 Q744.002 1004.94 744.002 1001.32 Q744.002 997.713 741.664 995.607 Q739.326 993.5 735.321 993.5 Q733.446 993.5 731.571 993.917 Q729.72 994.334 727.775 995.213 L727.775 977.852 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M661.34 841.967 Q657.729 841.967 655.9 845.532 Q654.095 849.073 654.095 856.203 Q654.095 863.309 655.9 866.874 Q657.729 870.416 661.34 870.416 Q664.974 870.416 666.78 866.874 Q668.609 863.309 668.609 856.203 Q668.609 849.073 666.78 845.532 Q664.974 841.967 661.34 841.967 M661.34 838.263 Q667.15 838.263 670.206 842.87 Q673.285 847.453 673.285 856.203 Q673.285 864.93 670.206 869.536 Q667.15 874.119 661.34 874.119 Q655.53 874.119 652.451 869.536 Q649.396 864.93 649.396 856.203 Q649.396 847.453 652.451 842.87 Q655.53 838.263 661.34 838.263 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M681.502 867.569 L686.386 867.569 L686.386 873.448 L681.502 873.448 L681.502 867.569 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M706.571 841.967 Q702.96 841.967 701.132 845.532 Q699.326 849.073 699.326 856.203 Q699.326 863.309 701.132 866.874 Q702.96 870.416 706.571 870.416 Q710.206 870.416 712.011 866.874 Q713.84 863.309 713.84 856.203 Q713.84 849.073 712.011 845.532 Q710.206 841.967 706.571 841.967 M706.571 838.263 Q712.382 838.263 715.437 842.87 Q718.516 847.453 718.516 856.203 Q718.516 864.93 715.437 869.536 Q712.382 874.119 706.571 874.119 Q700.761 874.119 697.683 869.536 Q694.627 864.93 694.627 856.203 Q694.627 847.453 697.683 842.87 Q700.761 838.263 706.571 838.263 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M736.733 841.967 Q733.122 841.967 731.294 845.532 Q729.488 849.073 729.488 856.203 Q729.488 863.309 731.294 866.874 Q733.122 870.416 736.733 870.416 Q740.368 870.416 742.173 866.874 Q744.002 863.309 744.002 856.203 Q744.002 849.073 742.173 845.532 Q740.368 841.967 736.733 841.967 M736.733 838.263 Q742.544 838.263 745.599 842.87 Q748.678 847.453 748.678 856.203 Q748.678 864.93 745.599 869.536 Q742.544 874.119 736.733 874.119 Q730.923 874.119 727.845 869.536 Q724.789 864.93 724.789 856.203 Q724.789 847.453 727.845 842.87 Q730.923 838.263 736.733 838.263 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M662.336 703.003 Q658.725 703.003 656.896 706.567 Q655.09 710.109 655.09 717.239 Q655.09 724.345 656.896 727.91 Q658.725 731.452 662.336 731.452 Q665.97 731.452 667.775 727.91 Q669.604 724.345 669.604 717.239 Q669.604 710.109 667.775 706.567 Q665.97 703.003 662.336 703.003 M662.336 699.299 Q668.146 699.299 671.201 703.905 Q674.28 708.489 674.28 717.239 Q674.28 725.965 671.201 730.572 Q668.146 735.155 662.336 735.155 Q656.525 735.155 653.447 730.572 Q650.391 725.965 650.391 717.239 Q650.391 708.489 653.447 703.905 Q656.525 699.299 662.336 699.299 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M682.498 728.604 L687.382 728.604 L687.382 734.484 L682.498 734.484 L682.498 728.604 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M701.595 730.549 L717.914 730.549 L717.914 734.484 L695.97 734.484 L695.97 730.549 Q698.632 727.794 703.215 723.165 Q707.821 718.512 709.002 717.169 Q711.247 714.646 712.127 712.91 Q713.03 711.151 713.03 709.461 Q713.03 706.706 711.085 704.97 Q709.164 703.234 706.062 703.234 Q703.863 703.234 701.409 703.998 Q698.979 704.762 696.201 706.313 L696.201 701.591 Q699.025 700.456 701.479 699.878 Q703.933 699.299 705.97 699.299 Q711.34 699.299 714.534 701.984 Q717.729 704.669 717.729 709.16 Q717.729 711.29 716.919 713.211 Q716.132 715.109 714.025 717.702 Q713.446 718.373 710.345 721.59 Q707.243 724.785 701.595 730.549 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M727.775 699.924 L746.131 699.924 L746.131 703.859 L732.057 703.859 L732.057 712.331 Q733.076 711.984 734.094 711.822 Q735.113 711.637 736.132 711.637 Q741.919 711.637 745.298 714.808 Q748.678 717.979 748.678 723.396 Q748.678 728.975 745.206 732.077 Q741.733 735.155 735.414 735.155 Q733.238 735.155 730.97 734.785 Q728.724 734.415 726.317 733.674 L726.317 728.975 Q728.4 730.109 730.622 730.665 Q732.845 731.22 735.321 731.22 Q739.326 731.22 741.664 729.114 Q744.002 727.007 744.002 723.396 Q744.002 719.785 741.664 717.678 Q739.326 715.572 735.321 715.572 Q733.446 715.572 731.571 715.989 Q729.72 716.405 727.775 717.285 L727.775 699.924 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M661.34 564.038 Q657.729 564.038 655.9 567.603 Q654.095 571.145 654.095 578.274 Q654.095 585.381 655.9 588.946 Q657.729 592.487 661.34 592.487 Q664.974 592.487 666.78 588.946 Q668.609 585.381 668.609 578.274 Q668.609 571.145 666.78 567.603 Q664.974 564.038 661.34 564.038 M661.34 560.335 Q667.15 560.335 670.206 564.941 Q673.285 569.525 673.285 578.274 Q673.285 587.001 670.206 591.608 Q667.15 596.191 661.34 596.191 Q655.53 596.191 652.451 591.608 Q649.396 587.001 649.396 578.274 Q649.396 569.525 652.451 564.941 Q655.53 560.335 661.34 560.335 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M681.502 589.64 L686.386 589.64 L686.386 595.52 L681.502 595.52 L681.502 589.64 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M696.618 560.96 L714.974 560.96 L714.974 564.895 L700.9 564.895 L700.9 573.367 Q701.919 573.02 702.937 572.858 Q703.956 572.673 704.974 572.673 Q710.761 572.673 714.141 575.844 Q717.521 579.015 717.521 584.432 Q717.521 590.011 714.048 593.112 Q710.576 596.191 704.257 596.191 Q702.081 596.191 699.812 595.821 Q697.567 595.45 695.16 594.71 L695.16 590.011 Q697.243 591.145 699.465 591.7 Q701.687 592.256 704.164 592.256 Q708.169 592.256 710.507 590.149 Q712.845 588.043 712.845 584.432 Q712.845 580.821 710.507 578.714 Q708.169 576.608 704.164 576.608 Q702.289 576.608 700.414 577.025 Q698.562 577.441 696.618 578.321 L696.618 560.96 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M736.733 564.038 Q733.122 564.038 731.294 567.603 Q729.488 571.145 729.488 578.274 Q729.488 585.381 731.294 588.946 Q733.122 592.487 736.733 592.487 Q740.368 592.487 742.173 588.946 Q744.002 585.381 744.002 578.274 Q744.002 571.145 742.173 567.603 Q740.368 564.038 736.733 564.038 M736.733 560.335 Q742.544 560.335 745.599 564.941 Q748.678 569.525 748.678 578.274 Q748.678 587.001 745.599 591.608 Q742.544 596.191 736.733 596.191 Q730.923 596.191 727.845 591.608 Q724.789 587.001 724.789 578.274 Q724.789 569.525 727.845 564.941 Q730.923 560.335 736.733 560.335 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M511.88 858.814 L529.735 858.814 L529.735 850.73 Q529.735 846.242 527.412 843.791 Q525.088 841.34 520.792 841.34 Q516.527 841.34 514.203 843.791 Q511.88 846.242 511.88 850.73 L511.88 858.814 M506.596 865.243 L506.596 850.73 Q506.596 842.741 510.224 838.667 Q513.821 834.561 520.792 834.561 Q527.826 834.561 531.422 838.667 Q535.019 842.741 535.019 850.73 L535.019 858.814 L554.116 858.814 L554.116 865.243 L506.596 865.243 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M510.256 790.351 L517.036 790.351 Q514.012 793.597 512.516 797.29 Q511.02 800.95 511.02 805.088 Q511.02 813.236 516.017 817.564 Q520.982 821.893 530.404 821.893 Q539.793 821.893 544.79 817.564 Q549.755 813.236 549.755 805.088 Q549.755 800.95 548.26 797.29 Q546.764 793.597 543.74 790.351 L550.456 790.351 Q552.747 793.725 553.893 797.512 Q555.039 801.268 555.039 805.469 Q555.039 816.259 548.451 822.466 Q541.83 828.672 530.404 828.672 Q518.945 828.672 512.357 822.466 Q505.737 816.259 505.737 805.469 Q505.737 801.204 506.882 797.449 Q507.996 793.661 510.256 790.351 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M528.494 760.368 Q529.481 755.753 532.6 753.175 Q535.719 750.565 540.302 750.565 Q547.337 750.565 551.188 755.403 Q555.039 760.241 555.039 769.153 Q555.039 772.145 554.434 775.328 Q553.861 778.479 552.684 781.853 L546.477 781.853 Q548.037 779.179 548.832 775.996 Q549.628 772.813 549.628 769.344 Q549.628 763.297 547.241 760.146 Q544.854 756.963 540.302 756.963 Q536.101 756.963 533.746 759.923 Q531.359 762.851 531.359 768.103 L531.359 773.641 L526.075 773.641 L526.075 767.848 Q526.075 763.106 524.197 760.591 Q522.287 758.077 518.723 758.077 Q515.062 758.077 513.121 760.687 Q511.147 763.265 511.147 768.103 Q511.147 770.745 511.72 773.768 Q512.293 776.792 513.503 780.42 L507.774 780.42 Q506.755 776.76 506.246 773.577 Q505.737 770.363 505.737 767.53 Q505.737 760.209 509.079 755.944 Q512.389 751.679 518.054 751.679 Q522.001 751.679 524.738 753.939 Q527.444 756.199 528.494 760.368 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip602)" cx="1527.09" cy="781.942" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1503.46" cy="931.157" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1619.63" cy="925.175" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1566.83" cy="865.597" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1531.93" cy="785.49" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1540.28" cy="946.322" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1518.18" cy="974.884" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1718.53" cy="951.304" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1591.24" cy="882.874" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1612.45" cy="975.476" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1596.67" cy="975.215" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1526.84" cy="892.212" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1513" cy="749.797" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1593.15" cy="817.931" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1511.04" cy="925.497" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1587.92" cy="769.743" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1702.55" cy="906.89" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1578.23" cy="796.193" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1596.47" cy="931.062" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1574.63" cy="826.878" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1426.72" cy="754.639" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1546.36" cy="1016.7" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1514.23" cy="850.172" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1525.13" cy="957.642" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1567.05" cy="832.539" r="14.4" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1260.45" cy="746.233" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1158.6" cy="751.302" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1173.07" cy="839.157" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1214.31" cy="901.847" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1183.96" cy="1012.77" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1232.84" cy="870.424" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1188.05" cy="750.137" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1289.14" cy="567.507" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1229.12" cy="668.987" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1208.91" cy="709.818" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1259.01" cy="667.847" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1187.45" cy="661.344" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1270.62" cy="576.454" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1197.56" cy="645.988" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1276.27" cy="658.213" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1217.34" cy="682.681" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1104.9" cy="801.482" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1245.62" cy="990.163" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1177.23" cy="454.698" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1180.04" cy="810.845" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1209.72" cy="776.622" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1211.39" cy="833.356" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1232.41" cy="859.329" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1244.7" cy="668.76" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1216.86" cy="826.01" r="14.4" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1074.12" cy="967.451" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1084.9" cy="820.324" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1072.4" cy="468.15" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1086.3" cy="456.143" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1140.01" cy="903.265" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1099.04" cy="741.712" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1050.76" cy="972.851" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1132.4" cy="1008.61" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1149.96" cy="700.403" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1067.31" cy="619.825" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1086.07" cy="1097.6" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1140.08" cy="737.773" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1143.49" cy="574.316" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1156.64" cy="904.526" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1154.07" cy="449.178" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1208.53" cy="554.083" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1144.09" cy="685.586" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1124.82" cy="472.019" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1125.09" cy="837.862" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1159.86" cy="729.512" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1182.58" cy="778.673" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1097.93" cy="873.459" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1145.31" cy="829.626" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1144.89" cy="818.532" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip602)" cx="1119.14" cy="988.537" r="14.4" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<path clip-path="url(#clip600)" d="M356.212 1377.32 L615.76 1377.32 L615.76 1169.96 L356.212 1169.96  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<polyline clip-path="url(#clip600)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="356.212,1377.32 615.76,1377.32 615.76,1169.96 356.212,1169.96 356.212,1377.32 "/>
<circle clip-path="url(#clip600)" cx="448.007" cy="1221.8" r="23.04" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="5.12"/>
<path clip-path="url(#clip600)" d="M553.645 1241.48 Q551.839 1246.11 550.126 1247.52 Q548.414 1248.94 545.543 1248.94 L542.14 1248.94 L542.14 1245.37 L544.64 1245.37 Q546.4 1245.37 547.372 1244.54 Q548.344 1243.7 549.525 1240.6 L550.289 1238.66 L539.802 1213.15 L544.316 1213.15 L552.418 1233.43 L560.52 1213.15 L565.034 1213.15 L553.645 1241.48 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M572.325 1235.14 L579.964 1235.14 L579.964 1208.77 L571.654 1210.44 L571.654 1206.18 L579.918 1204.52 L584.594 1204.52 L584.594 1235.14 L592.233 1235.14 L592.233 1239.08 L572.325 1239.08 L572.325 1235.14 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip600)" cx="448.007" cy="1273.64" r="23.04" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="5.12"/>
<path clip-path="url(#clip600)" d="M553.645 1293.32 Q551.839 1297.95 550.126 1299.36 Q548.414 1300.78 545.543 1300.78 L542.14 1300.78 L542.14 1297.21 L544.64 1297.21 Q546.4 1297.21 547.372 1296.38 Q548.344 1295.54 549.525 1292.44 L550.289 1290.5 L539.802 1264.99 L544.316 1264.99 L552.418 1285.27 L560.52 1264.99 L565.034 1264.99 L553.645 1293.32 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M575.543 1286.98 L591.862 1286.98 L591.862 1290.92 L569.918 1290.92 L569.918 1286.98 Q572.58 1284.23 577.163 1279.6 Q581.77 1274.94 582.95 1273.6 Q585.196 1271.08 586.075 1269.34 Q586.978 1267.58 586.978 1265.89 Q586.978 1263.14 585.034 1261.4 Q583.112 1259.67 580.011 1259.67 Q577.812 1259.67 575.358 1260.43 Q572.927 1261.19 570.15 1262.74 L570.15 1258.02 Q572.974 1256.89 575.427 1256.31 Q577.881 1255.73 579.918 1255.73 Q585.288 1255.73 588.483 1258.42 Q591.677 1261.1 591.677 1265.59 Q591.677 1267.72 590.867 1269.64 Q590.08 1271.54 587.973 1274.13 Q587.395 1274.8 584.293 1278.02 Q581.191 1281.22 575.543 1286.98 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip600)" cx="448.007" cy="1325.48" r="23.04" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="5.12"/>
<path clip-path="url(#clip600)" d="M553.645 1345.16 Q551.839 1349.79 550.126 1351.2 Q548.414 1352.62 545.543 1352.62 L542.14 1352.62 L542.14 1349.05 L544.64 1349.05 Q546.4 1349.05 547.372 1348.22 Q548.344 1347.38 549.525 1344.28 L550.289 1342.34 L539.802 1316.83 L544.316 1316.83 L552.418 1337.11 L560.52 1316.83 L565.034 1316.83 L553.645 1345.16 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip600)" d="M585.682 1324.12 Q589.038 1324.84 590.913 1327.11 Q592.811 1329.38 592.811 1332.71 Q592.811 1337.82 589.293 1340.63 Q585.774 1343.43 579.293 1343.43 Q577.117 1343.43 574.802 1342.99 Q572.511 1342.57 570.057 1341.71 L570.057 1337.2 Q572.001 1338.33 574.316 1338.91 Q576.631 1339.49 579.154 1339.49 Q583.552 1339.49 585.844 1337.76 Q588.159 1336.02 588.159 1332.71 Q588.159 1329.65 586.006 1327.94 Q583.876 1326.2 580.057 1326.2 L576.029 1326.2 L576.029 1322.36 L580.242 1322.36 Q583.691 1322.36 585.52 1321 Q587.349 1319.61 587.349 1317.01 Q587.349 1314.35 585.45 1312.94 Q583.575 1311.51 580.057 1311.51 Q578.136 1311.51 575.937 1311.92 Q573.737 1312.34 571.099 1313.22 L571.099 1309.05 Q573.761 1308.31 576.075 1307.94 Q578.413 1307.57 580.474 1307.57 Q585.798 1307.57 588.899 1310 Q592.001 1312.41 592.001 1316.53 Q592.001 1319.4 590.358 1321.39 Q588.714 1323.36 585.682 1324.12 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /></svg>
<h2 id="Linear-Principal-Component-Analysis"><a class="docs-heading-anchor" href="#Linear-Principal-Component-Analysis">Linear Principal Component Analysis</a><a id="Linear-Principal-Component-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-Principal-Component-Analysis" title="Permalink"></a></h2><p>This package uses the <a href="#MultivariateStats.PCA"><code>PCA</code></a> type to define a linear PCA model:</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.PCA" href="#MultivariateStats.PCA"><code>MultivariateStats.PCA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Linear Principal Component Analysis</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L3-L5">source</a></section></article><p>This type comes with several methods where <span>$M$</span> be an instance of  <a href="#MultivariateStats.PCA"><code>PCA</code></a>, <span>$d$</span> be the dimension of observations, and <span>$p$</span> be the output dimension (<em>i.e</em> the dimension of the principal subspace).</p><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit-Union{Tuple{T}, Tuple{Type{PCA}, AbstractMatrix{T}}} where T&lt;:Real" href="#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{PCA}, AbstractMatrix{T}}} where T&lt;:Real"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit(PCA, X; ...)</code></pre><p>Perform PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an <strong>observation</strong>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:auto</code>: use <code>:cov</code> when <code>d &lt; n</code> or <code>:svd</code> otherwise (<em>default</em>).</li><li><code>:cov</code>: based on covariance matrix decomposition.</li><li><code>:svd</code>: based on SVD of the input data.</li></ul></li><li><code>maxoutdim</code>: The output dimension, i.e. dimension of the transformed space (<em>min(d, nc-1)</em>)</li><li><code>pratio</code>: The ratio of variances preserved in the principal subspace (<em>0.99</em>)</li><li><code>mean</code>: The mean vector, which can be either of<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li></ul><p><strong>Notes:</strong></p><ul><li><p>The output dimension <code>p</code> depends on both <code>maxoutdim</code> and <code>pratio</code>, as follows. Suppose the first <code>k</code> principal components preserve at least <code>pratio</code> of the total variance, while the first <code>k-1</code> preserves less than <code>pratio</code>, then the actual output dimension will be <span>$\min(k, maxoutdim)$</span>.</p></li><li><p>This function calls <a href="#MultivariateStats.pcacov"><code>pcacov</code></a> or <a href="#MultivariateStats.pcasvd"><code>pcasvd</code></a> internally, depending on the choice of method.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L255-L280">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.predict-Union{Tuple{T}, Tuple{PCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#StatsAPI.predict-Union{Tuple{T}, Tuple{PCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>StatsAPI.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(M::PCA, x::AbstractVecOrMat{&lt;:Real})</code></pre><p>Given a PCA model <code>M</code>, transform observations <code>x</code> into principal components space, as</p><p class="math-container">\[\mathbf{y} = \mathbf{P}^T (\mathbf{x} - \boldsymbol{\mu})\]</p><p>Here, <code>x</code> can be either a vector of length <code>d</code> or a matrix where each column is an observation, and <code>\mathbf{P}</code> is the projection matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L112-L121">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{PCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{PCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>MultivariateStats.reconstruct</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reconstruct(M::PCA, y::AbstractVecOrMat{&lt;:Real})</code></pre><p>Given a PCA model <code>M</code>, returns a (approximately) reconstructed observations from principal components space, as</p><p class="math-container">\[\tilde{\mathbf{x}} = \mathbf{P} \mathbf{y} + \boldsymbol{\mu}\]</p><p>Here, <code>y</code> can be either a vector of length <code>p</code> or a matrix where each column gives the principal components for an observation, and <span>$\mathbf{P}$</span> is the projection matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L124-L134">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.size-Tuple{PCA}" href="#Base.size-Tuple{PCA}"><code>Base.size</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">size(M)</code></pre><p>Returns a tuple with the dimensions of input (the dimension of the observation space) and output (the dimension of the principal subspace).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.mean-Tuple{PCA}" href="#Statistics.mean-Tuple{PCA}"><code>Statistics.mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mean(M::PCA)</code></pre><p>Returns the mean vector (of length <code>d</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L36-L40">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.projection-Tuple{PCA}" href="#MultivariateStats.projection-Tuple{PCA}"><code>MultivariateStats.projection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">projection(M::PCA)</code></pre><p>Returns the projection matrix (of size <code>(d, p)</code>). Each column of the projection matrix corresponds to a principal component. The principal components are arranged in descending order of the corresponding variances.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L43-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.var-Tuple{PCA}" href="#Statistics.var-Tuple{PCA}"><code>Statistics.var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">var(M::PCA)</code></pre><p>Returns the total observation variance, which is equal to <code>tprincipalvar(M) + tresidualvar(M)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L87-L91">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.principalvars-Tuple{PCA}" href="#MultivariateStats.principalvars-Tuple{PCA}"><code>MultivariateStats.principalvars</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">principalvars(M::PCA)</code></pre><p>Returns the variances of principal components.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L58-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.tprincipalvar-Tuple{PCA}" href="#MultivariateStats.tprincipalvar-Tuple{PCA}"><code>MultivariateStats.tprincipalvar</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tprincipalvar(M::PCA)</code></pre><p>Returns the total variance of principal components, which is equal to <code>sum(principalvars(M))</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L73-L77">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.tresidualvar-Tuple{PCA}" href="#MultivariateStats.tresidualvar-Tuple{PCA}"><code>MultivariateStats.tresidualvar</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tresidualvar(M::PCA)</code></pre><p>Returns the total residual variance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L80-L84">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.r2-Tuple{PCA}" href="#StatsAPI.r2-Tuple{PCA}"><code>StatsAPI.r2</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">r2(M::PCA)
principalratio(M::PCA)</code></pre><p>Returns the ratio of variance preserved in the principal subspace, which is equal to <code>tprincipalvar(M) / var(M)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L94-L99">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.loadings-Tuple{PCA}" href="#MultivariateStats.loadings-Tuple{PCA}"><code>MultivariateStats.loadings</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">loadings(M::PCA)</code></pre><p>Returns model loadings, i.e. the weights for each original variable when calculating the principal component.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L103-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvals-Tuple{PCA}" href="#LinearAlgebra.eigvals-Tuple{PCA}"><code>LinearAlgebra.eigvals</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eigvals(M::PCA)</code></pre><p>Get the eigenvalues of the PCA model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L66-L70">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvecs-Tuple{PCA}" href="#LinearAlgebra.eigvecs-Tuple{PCA}"><code>LinearAlgebra.eigvecs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eigvecs(M::PCA)</code></pre><p>Get the eigenvalues of the PCA model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L51-L55">source</a></section></article><p>Auxiliary functions:</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.pcacov" href="#MultivariateStats.pcacov"><code>MultivariateStats.pcacov</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pcacov(C, mean; ...)</code></pre><p>Compute and return a PCA model based on eigenvalue decomposition of a given covariance matrix <code>C</code>.</p><p><strong>Parameters:</strong></p><ul><li><code>C</code>: The covariance matrix of the samples.</li><li><code>mean</code>: The mean vector of original samples, which can be a vector of length <code>d</code>,          or an empty vector <code>Float64[]</code> indicating a zero mean.</li></ul><p><em>Note:</em> This function accepts two keyword arguments: <code>maxoutdim</code> and <code>pratio</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L197-L208">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.pcasvd" href="#MultivariateStats.pcasvd"><code>MultivariateStats.pcasvd</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pcasvd(Z, mean, tw; ...)</code></pre><p>Compute and return a PCA model based on singular value decomposition of a centralized sample matrix <code>Z</code>.</p><p><strong>Parameters:</strong></p><ul><li><code>Z</code>: a matrix of centralized samples.</li><li><code>mean</code>: The mean vector of the <strong>original</strong> samples, which can be a vector of length <code>d</code>,         or an empty vector <code>Float64[]</code> indicating a zero mean.</li><li><code>n</code>: a number of samples.</li></ul><p><em>Note:</em> This function accepts two keyword arguments: <code>maxoutdim</code> and <code>pratio</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L223-L235">source</a></section></article><h2 id="Kernel-Principal-Component-Analysis"><a class="docs-heading-anchor" href="#Kernel-Principal-Component-Analysis">Kernel Principal Component Analysis</a><a id="Kernel-Principal-Component-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-Principal-Component-Analysis" title="Permalink"></a></h2><p><a href="https://en.wikipedia.org/wiki/Kernel_principal_component_analysis&gt;">Kernel Principal Component Analysis</a> (kernel PCA) is an extension of principal component analysis (PCA) using techniques of kernel methods. Using a kernel, the originally linear operations of PCA are performed in a reproducing kernel Hilbert space.</p><p>This package defines a <a href="#MultivariateStats.KernelPCA"><code>KernelPCA</code></a> type to represent a kernel PCA model.</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.KernelPCA" href="#MultivariateStats.KernelPCA"><code>MultivariateStats.KernelPCA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This type contains kernel PCA model parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L31-L33">source</a></section></article><p>The package provides a set of methods to access the properties of the kernel PCA model. Let <span>$M$</span> be an instance of <a href="#MultivariateStats.KernelPCA"><code>KernelPCA</code></a>, <span>$d$</span> be the dimension of observations, and <span>$p$</span> be the output dimension (<em>i.e</em> the dimension of the principal subspace).</p><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit-Union{Tuple{T}, Tuple{Type{KernelPCA}, AbstractMatrix{T}}} where T&lt;:Real" href="#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{KernelPCA}, AbstractMatrix{T}}} where T&lt;:Real"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit(KernelPCA, X; ...)</code></pre><p>Perform kernel PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an observation.</p><p>This method returns an instance of <a href="#MultivariateStats.KernelPCA"><code>KernelPCA</code></a>.</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>kernel</code>: The kernel function. This functions accepts two vector arguments <code>x</code> and <code>y</code>,</li></ul><p>and returns a scalar value (<em>default:</em> <code>(x,y)-&gt;x&#39;y</code>). If set to <code>nothing</code>, the matrix <code>X</code> is the pre-computed symmetric kernel (Gram) matrix.</p><ul><li><code>solver</code>: The choice of solver:<ul><li><code>:eig</code>: uses <code>LinearAlgebra.eigen</code> (<em>default</em>)</li><li><code>:eigs</code>: uses <code>Arpack.eigs</code> (always used for sparse data)</li></ul></li><li><code>maxoutdim</code>:  Maximum output dimension (<em>default</em> <code>min(d, n)</code>)</li><li><code>inverse</code>: Whether to perform calculation for inverse transform for non-precomputed kernels (<em>default</em> <code>false</code>)</li><li><code>β</code>: Hyperparameter of the ridge regression that learns the inverse transform (<em>default</em> <code>1</code> when <code>inverse</code> is <code>true</code>).</li><li><code>tol</code>: Convergence tolerance for <code>eigs</code> solver (<em>default</em> <code>0.0</code>)</li><li><code>maxiter</code>: Maximum number of iterations for <code>eigs</code> solver (<em>default</em> <code>300</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L123-L145">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.predict-Tuple{KernelPCA}" href="#StatsAPI.predict-Tuple{KernelPCA}"><code>StatsAPI.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(M::KernelPCA)</code></pre><p>Transform the data fitted to the model <code>M</code> to a kernel space of the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L91-L95">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.predict-Union{Tuple{T}, Tuple{KernelPCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#StatsAPI.predict-Union{Tuple{T}, Tuple{KernelPCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>StatsAPI.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(M::KernelPCA, x)</code></pre><p>Transform out-of-sample transformation of <code>x</code> into a kernel space of the model <code>M</code>.</p><p>Here, <code>x</code> can be either a vector of length <code>d</code> or a matrix where each column is an observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L77-L83">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{KernelPCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{KernelPCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>MultivariateStats.reconstruct</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reconstruct(M::KernelPCA, y)</code></pre><p>Approximately reconstruct observations, given in <code>y</code>, to the original space using the kernel PCA model <code>M</code>.</p><p>Here, <code>y</code> can be either a vector of length <code>p</code> or a matrix where each column gives the principal components for an observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L99-L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.size-Tuple{KernelPCA}" href="#Base.size-Tuple{KernelPCA}"><code>Base.size</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">size(M::KernelPCA)</code></pre><p>Returns a tuple with the input dimension <span>$d$</span>, <em>i.e</em> the dimension of the observation space, and the output dimension <span>$p$</span>, <em>i.e</em> the dimension of the principal subspace.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L44-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.projection-Tuple{KernelPCA}" href="#MultivariateStats.projection-Tuple{KernelPCA}"><code>MultivariateStats.projection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">projection(M::KernelPCA)</code></pre><p>Return the projection matrix (of size <span>$n \times p$</span>). Each column of the projection matrix corresponds to an eigenvector, and <span>$n$</span> is a number of observations.</p><p>The principal components are arranged in descending order of the corresponding eigenvalues.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L65-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvals-Tuple{KernelPCA}" href="#LinearAlgebra.eigvals-Tuple{KernelPCA}"><code>LinearAlgebra.eigvals</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eigvals(M::KernelPCA)</code></pre><p>Return eigenvalues of the kernel matrix of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L51-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.eigvecs-Tuple{KernelPCA}" href="#LinearAlgebra.eigvecs-Tuple{KernelPCA}"><code>LinearAlgebra.eigvecs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eigvecs(M::KernelPCA)</code></pre><p>Return eigenvectors of the kernel matrix of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L58-L62">source</a></section></article><h3 id="Kernels"><a class="docs-heading-anchor" href="#Kernels">Kernels</a><a id="Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Kernels" title="Permalink"></a></h3><p>List of the commonly used kernels:</p><table><tr><th style="text-align: right">function</th><th style="text-align: right">description</th></tr><tr><td style="text-align: right"><code>(x,y)-&gt;x&#39;y</code></td><td style="text-align: right">Linear</td></tr><tr><td style="text-align: right"><code>(x,y)-&gt;(x&#39;y+c)^d</code></td><td style="text-align: right">Polynomial</td></tr><tr><td style="text-align: right"><code>(x,y)-&gt;exp(-γ*norm(x-y)^2.0)</code></td><td style="text-align: right">Radial basis function (RBF)</td></tr></table><p>This package has a separate interface for adjusting kernel matrices.</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.KernelCenter" href="#MultivariateStats.KernelCenter"><code>MultivariateStats.KernelCenter</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Center a kernel matrix</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit-Tuple{Type{MultivariateStats.KernelCenter}, AbstractMatrix{&lt;:Real}}" href="#StatsAPI.fit-Tuple{Type{MultivariateStats.KernelCenter}, AbstractMatrix{&lt;:Real}}"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Fit <code>KernelCenter</code> object</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.transform!-Tuple{MultivariateStats.KernelCenter, AbstractMatrix{&lt;:Real}}" href="#MultivariateStats.transform!-Tuple{MultivariateStats.KernelCenter, AbstractMatrix{&lt;:Real}}"><code>MultivariateStats.transform!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Center kernel matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L18">source</a></section></article><h2 id="Probabilistic-Principal-Component-Analysis"><a class="docs-heading-anchor" href="#Probabilistic-Principal-Component-Analysis">Probabilistic Principal Component Analysis</a><a id="Probabilistic-Principal-Component-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilistic-Principal-Component-Analysis" title="Permalink"></a></h2><p><a href="https://www.microsoft.com/en-us/research/publication/probabilistic-principal-component-analysis">Probabilistic Principal Component Analysis</a> (PPCA) represents a constrained form of the Gaussian distribution in which the number of free parameters can be restricted while still allowing the model to capture the dominant correlations in a data set. It is expressed as the maximum likelihood solution of a probabilistic latent variable model<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>.</p><p>This package defines a <a href="#MultivariateStats.PPCA"><code>PPCA</code></a> type to represent a probabilistic PCA model, and provides a set of methods to access the properties.</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.PPCA" href="#MultivariateStats.PPCA"><code>MultivariateStats.PPCA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This type contains probabilistic PCA model parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L3-L5">source</a></section></article><p>Let <span>$M$</span> be an instance of <a href="#MultivariateStats.PPCA"><code>PPCA</code></a>, <span>$d$</span> be the dimension of observations, and <span>$p$</span> be the output dimension (<em>i.e</em> the dimension of the principal subspace).</p><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit" href="#StatsAPI.fit"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">fit(Whitening, X::AbstractMatrix{T}; kwargs...)</code></pre><p>Estimate a whitening transform from the data given in <code>X</code>.</p><p>This function returns an instance of <a href="../whiten/#MultivariateStats.Whitening"><code>Whitening</code></a></p><p><strong>Keyword Arguments:</strong></p><ul><li><p><code>regcoef</code>: The regularization coefficient. The covariance will be regularized as follows when <code>regcoef</code> is positive <code>C + (eigmax(C) * regcoef) * eye(d)</code>. Default values is <code>zero(T)</code>.</p></li><li><p><code>dims</code>: if <code>1</code> the transformation calculated from the row samples. fit standardization parameters in column-wise fashion; if <code>2</code> the transformation calculated from the column samples. The default is <code>nothing</code>, which is equivalent to <code>dims=2</code> with a deprecation warning.</p></li><li><p><code>mean</code>: The mean vector, which can be either of:</p><ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<strong>default</strong>)</li><li>a pre-computed mean vector</li></ul></li></ul><p><strong>Note:</strong> This function internally relies on <a href="../whiten/#MultivariateStats.cov_whitening"><code>cov_whitening</code></a> to derive the transformation <code>W</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/whiten.jl#L104-L123">source</a></section><section><div><pre><code class="language-julia hljs">fit(PCA, X; ...)</code></pre><p>Perform PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an <strong>observation</strong>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:auto</code>: use <code>:cov</code> when <code>d &lt; n</code> or <code>:svd</code> otherwise (<em>default</em>).</li><li><code>:cov</code>: based on covariance matrix decomposition.</li><li><code>:svd</code>: based on SVD of the input data.</li></ul></li><li><code>maxoutdim</code>: The output dimension, i.e. dimension of the transformed space (<em>min(d, nc-1)</em>)</li><li><code>pratio</code>: The ratio of variances preserved in the principal subspace (<em>0.99</em>)</li><li><code>mean</code>: The mean vector, which can be either of<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li></ul><p><strong>Notes:</strong></p><ul><li><p>The output dimension <code>p</code> depends on both <code>maxoutdim</code> and <code>pratio</code>, as follows. Suppose the first <code>k</code> principal components preserve at least <code>pratio</code> of the total variance, while the first <code>k-1</code> preserves less than <code>pratio</code>, then the actual output dimension will be <span>$\min(k, maxoutdim)$</span>.</p></li><li><p>This function calls <a href="#MultivariateStats.pcacov"><code>pcacov</code></a> or <a href="#MultivariateStats.pcasvd"><code>pcasvd</code></a> internally, depending on the choice of method.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/pca.jl#L255-L280">source</a></section><section><div><pre><code class="nohighlight hljs">fit(PPCA, X; ...)</code></pre><p>Perform probabilistic PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an observation. This method returns an instance of <a href="#MultivariateStats.PPCA"><code>PPCA</code></a>.</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:ml</code>: use maximum likelihood version of probabilistic PCA (<em>default</em>)</li><li><code>:em</code>: use EM version of probabilistic PCA</li><li><code>:bayes</code>: use Bayesian PCA</li></ul></li><li><code>maxoutdim</code>: Maximum output dimension (<em>default</em> <code>d-1</code>)</li><li><code>mean</code>: The mean vector, which can be either of:<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li><li><code>tol</code>: Convergence tolerance (<em>default</em> <code>1.0e-6</code>)</li><li><code>maxiter</code>: Maximum number of iterations (<em>default</em> <code>1000</code>)</li></ul><p><strong>Notes:</strong> This function calls <a href="#MultivariateStats.ppcaml"><code>ppcaml</code></a>, <a href="#MultivariateStats.ppcaem"><code>ppcaem</code></a> or <a href="#MultivariateStats.bayespca"><code>bayespca</code></a> internally, depending on the choice of method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L280-L305">source</a></section><section><div><p>Fit <code>KernelCenter</code> object</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L11">source</a></section><section><div><pre><code class="language-julia hljs">fit(KernelPCA, X; ...)</code></pre><p>Perform kernel PCA over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an observation.</p><p>This method returns an instance of <a href="#MultivariateStats.KernelPCA"><code>KernelPCA</code></a>.</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>kernel</code>: The kernel function. This functions accepts two vector arguments <code>x</code> and <code>y</code>,</li></ul><p>and returns a scalar value (<em>default:</em> <code>(x,y)-&gt;x&#39;y</code>). If set to <code>nothing</code>, the matrix <code>X</code> is the pre-computed symmetric kernel (Gram) matrix.</p><ul><li><code>solver</code>: The choice of solver:<ul><li><code>:eig</code>: uses <code>LinearAlgebra.eigen</code> (<em>default</em>)</li><li><code>:eigs</code>: uses <code>Arpack.eigs</code> (always used for sparse data)</li></ul></li><li><code>maxoutdim</code>:  Maximum output dimension (<em>default</em> <code>min(d, n)</code>)</li><li><code>inverse</code>: Whether to perform calculation for inverse transform for non-precomputed kernels (<em>default</em> <code>false</code>)</li><li><code>β</code>: Hyperparameter of the ridge regression that learns the inverse transform (<em>default</em> <code>1</code> when <code>inverse</code> is <code>true</code>).</li><li><code>tol</code>: Convergence tolerance for <code>eigs</code> solver (<em>default</em> <code>0.0</code>)</li><li><code>maxiter</code>: Maximum number of iterations for <code>eigs</code> solver (<em>default</em> <code>300</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/kpca.jl#L123-L145">source</a></section><section><div><pre><code class="language-julia hljs">fit(CCA, X, Y; ...)</code></pre><p>Perform CCA over the data given in matrices <code>X</code> and <code>Y</code>. Each column of <code>X</code> and <code>Y</code> is an observation.</p><p><code>X</code> and <code>Y</code> should have the same number of columns (denoted by <code>n</code> below).</p><p>This method returns an instance of <a href="../cca/#MultivariateStats.CCA"><code>CCA</code></a>.</p><p><strong>Keyword arguments:</strong></p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:cov</code>: based on covariance matrices</li><li><code>:svd</code>: based on SVD of the input data (<em>default</em>)</li></ul></li><li><code>outdim</code>: The output dimension, <em>i.e</em> dimension of the common space (<em>default</em>: <code>min(dx, dy, n)</code>)</li><li><code>mean</code>: The mean vector, which can be either of:<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li></ul><p><strong>Notes:</strong> This function calls <a href="../cca/#MultivariateStats.ccacov"><code>ccacov</code></a> or <a href="../cca/#MultivariateStats.ccasvd"><code>ccasvd</code></a> internally, depending on the choice of method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/cca.jl#L283-L304">source</a></section><section><div><pre><code class="language-julia hljs">fit(MDS, X; kwargs...)</code></pre><p>Compute an embedding of <code>X</code> points by classical multidimensional scaling (MDS). There are two calling options, specified via the required keyword argument <code>distances</code>:</p><pre><code class="nohighlight hljs">mds = fit(MDS, X; distances=false, maxoutdim=size(X,1)-1)</code></pre><p>where <code>X</code> is the data matrix. Distances between pairs of columns of <code>X</code> are computed using the Euclidean norm. This is equivalent to performing PCA on <code>X</code>.</p><pre><code class="nohighlight hljs">mds = fit(MDS, D; distances=true, maxoutdim=size(D,1)-1)</code></pre><p>where <code>D</code> is a symmetric matrix <code>D</code> of distances between points.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/cmds.jl#L217-L231">source</a></section><section><div><pre><code class="language-julia hljs">fit(MetricMDS, X; kwargs...)</code></pre><p>Compute an embedding of <code>X</code> points by (non)metric multidimensional scaling (MDS).</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>distances</code>: The choice of input (<em>required</em>):<ul><li><code>false</code>: use <code>X</code> to calculate dissimilarity matrix using Euclidean distance</li><li><code>true</code>: use <code>X</code> input as precomputed dissimilarity symmetric matrix (distances)</li></ul></li><li><code>maxoutdim</code>: Maximum output dimension (<em>default</em> <code>d-1</code>)</li><li><code>metric</code> : a function for calculation of disparity values<ul><li><code>nothing</code>: use dissimilarity values as the disparities to perform the metric MDS (<em>default</em>)</li><li><code>isotonic</code>: converts dissimilarity values to ordinal disparities to perform non-metric MDS</li><li>any two parameter disparity transformation function, where the first parameter is a vector of proximities (i.e. dissimilarities) and the second parameter is a vector of distances, e.g. <code>(p,d)-&gt;b*p</code> for some <code>b</code> is a transformation function for <em>ratio</em> MDS.</li></ul></li><li><code>tol</code>: Convergence tolerance (<em>default</em> <code>1.0e-3</code>)</li><li><code>maxiter</code>: Maximum number of iterations (<em>default</em> <code>300</code>)</li><li><code>initial</code>: an initial reduced space point configuration<ul><li><code>nothing</code>: then an initial configuration is randomly generated (<em>default</em>)</li><li>pre-defined matrix</li></ul></li><li><code>weights</code>: a weight matrix<ul><li><code>nothing</code>: then weights are set to one, <span>$w_{ij} = 1$</span> (<em>default</em>)</li><li>pre-defined matrix</li></ul></li></ul><p><em>Note:</em> if the algorithm is unable to converge then <code>ConvergenceException</code> is thrown.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/mmds.jl#L97-L124">source</a></section><section><div><pre><code class="language-julia hljs">fit(LinearDiscriminant, Xp, Xn; covestimator = SimpleCovariance())</code></pre><p>Performs LDA given both positive and negative samples. The function accepts follwing parameters:</p><p><strong>Parameters</strong></p><ul><li><code>Xp</code>: The sample matrix of the positive class.</li><li><code>Xn</code>: The sample matrix of the negative class.</li></ul><p><strong>Keyword arguments:</strong></p><ul><li><code>covestimator</code>: Custom covariance estimator for between-class covariance. The covariance matrix will be calculated as <code>cov(covestimator_between, #=data=#; dims=2, mean=zeros(#=...=#)</code>. Custom covariance estimators, available in other packages, may result in more robust discriminants for data with more features than observations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/lda.jl#L128-L139">source</a></section><section><div><pre><code class="language-julia hljs">fit(MulticlassLDA, X, y; ...)</code></pre><p>Perform multi-class LDA over a given data set <code>X</code> with corresponding labels <code>y</code> with <code>nc</code> number of classes.</p><p>This function returns the resultant multi-class LDA model as an instance of <a href="../lda/#MultivariateStats.MulticlassLDA"><code>MulticlassLDA</code></a>.</p><p><em>Parameters</em></p><ul><li><code>X</code>:   the matrix of input samples, of size <code>(d, n)</code>. Each column in <code>X</code> is an observation.</li><li><code>y</code>:   the vector of class labels, of length <code>n</code>.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:gevd</code>: based on generalized eigenvalue decomposition (<em>default</em>).</li><li><code>:whiten</code>: first derive a whitening transform from <code>Sw</code> and then solve the problem based on eigenvalue</li></ul>decomposition of the whiten <code>Sb</code>.</li><li><code>outdim</code>: The output dimension, i.e. dimension of the transformed space <code>min(d, nc-1)</code></li><li><code>regcoef</code>: The regularization coefficient (<em>default:</em> <code>1.0e-6</code>). A positive value <code>regcoef * eigmax(Sw)</code>   is added to the diagonal of <code>Sw</code> to improve numerical stability.</li><li><code>covestimator_between</code>: Custom covariance estimator for between-class covariance (<em>default:</em> <code>SimpleCovariance()</code>).   The covariance matrix will be calculated as <code>cov(covestimator_between, #=data=#; dims=2, mean=zeros(#=...=#))</code>.   Custom covariance estimators, available in other packages, may result in more robust discriminants for data   with more features than observations.</li><li><code>covestimator_within</code>:  Custom covariance estimator for within-class covariance (<em>default:</em> <code>SimpleCovariance()</code>).   The covariance matrix will be calculated as <code>cov(covestimator_within, #=data=#; dims=2, mean=zeros(nc))</code>.   Custom covariance estimators, available in other packages, may result in more robust discriminants for data   with more features than observations.</li></ul><p><strong>Notes:</strong></p><p>The resultant projection matrix <span>$P$</span> satisfies:</p><p class="math-container">\[\mathbf{P}^T (\mathbf{S}_w + \kappa \mathbf{I}) \mathbf{P} = \mathbf{I}\]</p><p>Here, <span>$\kappa$</span> equals <code>regcoef * eigmax(Sw)</code>. The columns of <span>$P$</span> are arranged in descending order of the corresponding generalized eigenvalues.</p><p>Note that <a href="../lda/#MultivariateStats.MulticlassLDA"><code>MulticlassLDA</code></a> does not currently support the normalized version using <span>$\mathbf{S}_w^*$</span> and <span>$\mathbf{S}_b^*$</span> (see <a href="../lda/#MultivariateStats.SubspaceLDA"><code>SubspaceLDA</code></a>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/lda.jl#L286-L328">source</a></section><section><div><pre><code class="language-julia hljs">fit(SubspaceLDA, X, y; normalize=true)</code></pre><p>Fit an subspace projection of LDA model over a given data set <code>X</code> with corresponding labels <code>y</code> using the equivalent of <span>$\mathbf{S}_w^*$</span> and <span>$\mathbf{S}_b^*$</span>`.</p><p>Note: Subspace LDA also supports the normalized version of LDA via the <code>normalize</code> keyword.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/lda.jl#L453-L460">source</a></section><section><div><pre><code class="language-julia hljs">fit(ICA, X, k; ...)</code></pre><p>Perform ICA over the data set given in <code>X</code>.</p><p><strong>Parameters:</strong> -<code>X</code>: The data matrix, of size <span>$(m, n)$</span>. Each row corresponds to a mixed signal, while each column corresponds to an observation (<em>e.g</em> all signal value at a particular time step). -<code>k</code>: The number of independent components to recover.</p><p><strong>Keyword Arguments:</strong></p><ul><li><code>alg</code>: The choice of algorithm (<em>default</em> <code>:fastica</code>)</li><li><code>fun</code>: The approx neg-entropy functor (<em>default</em> <a href="../ica/#MultivariateStats.Tanh"><code>Tanh</code></a>)</li><li><code>do_whiten</code>: Whether to perform pre-whitening (<em>default</em> <code>true</code>)</li><li><code>maxiter</code>: Maximum number of iterations (<em>default</em> <code>100</code>)</li><li><code>tol</code>: Tolerable change of <span>$W$</span> at convergence (<em>default</em> <code>1.0e-6</code>)</li><li><code>mean</code>: The mean vector, which can be either of:<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li><li><code>winit</code>: Initial guess of <span>$W$</span>, which should be either of:<ul><li>empty matrix: the function will perform random initialization (<em>default</em>)</li><li>a matrix of size <span>$(k, k)$</span> (when <code>do_whiten</code>)</li><li>a matrix of size <span>$(m, k)$</span> (when <code>!do_whiten</code>)</li></ul></li></ul><p>Returns the resultant ICA model, an instance of type <a href="../ica/#MultivariateStats.ICA"><code>ICA</code></a>.</p><p><strong>Note:</strong> If <code>do_whiten</code> is <code>true</code>, the return <code>W</code> satisfies <span>$\mathbf{W}^T \mathbf{C} \mathbf{W} = \mathbf{I}$</span>, otherwise <span>$W$</span> is orthonormal, <em>i.e</em> <span>$\mathbf{W}^T \mathbf{W} = \mathbf{I}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ica.jl#L181-L211">source</a></section><section><div><pre><code class="language-julia hljs">fit(FactorAnalysis, X; ...)</code></pre><p>Perform factor analysis over the data given in a matrix <code>X</code>. Each column of <code>X</code> is an observation. This method returns an instance of <a href="../fa/#MultivariateStats.FactorAnalysis"><code>FactorAnalysis</code></a>.</p><p><strong>Keyword arguments:</strong></p><p>Let <code>(d, n) = size(X)</code> be respectively the input dimension and the number of observations:</p><ul><li><code>method</code>: The choice of methods:<ul><li><code>:em</code>: use EM version of factor analysis</li><li><code>:cm</code>: use CM version of factor analysis (<em>default</em>)</li></ul></li><li><code>maxoutdim</code>: Maximum output dimension (<em>default</em> <code>d-1</code>)</li><li><code>mean</code>: The mean vector, which can be either of:<ul><li><code>0</code>: the input data has already been centralized</li><li><code>nothing</code>: this function will compute the mean (<em>default</em>)</li><li>a pre-computed mean vector</li></ul></li><li><code>tol</code>: Convergence tolerance (<em>default</em> <code>1.0e-6</code>)</li><li><code>maxiter</code>: Maximum number of iterations (<em>default</em> <code>1000</code>)</li><li><code>η</code>: Variance low bound (<em>default</em> <code>1.0e-6</code>)</li></ul><p><strong>Notes:</strong> This function calls <a href="../fa/#MultivariateStats.facm"><code>facm</code></a> or <a href="../fa/#MultivariateStats.faem"><code>faem</code></a> internally, depending on the choice of method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/fa.jl#L232-L256">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.size-Tuple{PPCA}" href="#Base.size-Tuple{PPCA}"><code>Base.size</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">size(M::PPCA)</code></pre><p>Returns a tuple with values of the input dimension <span>$d$</span>, <em>i.e</em> the dimension of the observation space, and the output dimension <span>$p$</span>, <em>i.e</em> the dimension of the principal subspace.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L13-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.mean-Tuple{PPCA}" href="#Statistics.mean-Tuple{PPCA}"><code>Statistics.mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mean(M::PPCA)</code></pre><p>Get the mean vector (of length <span>$d$</span>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L22-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.var-Tuple{PPCA}" href="#Statistics.var-Tuple{PPCA}"><code>Statistics.var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">var(M::PPCA)</code></pre><p>Returns the total residual variance of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L40-L44">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{PPCA}" href="#Statistics.cov-Tuple{PPCA}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">cov(M::PPCA)</code></pre><p>Returns the covariance of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L54-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.projection-Tuple{PPCA}" href="#MultivariateStats.projection-Tuple{PPCA}"><code>MultivariateStats.projection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">projection(M::PPCA)</code></pre><p>Returns the projection matrix (of size <span>$(d, p)$</span>). Each column of the projection matrix corresponds to a principal component.</p><p>The principal components are arranged in descending order of the corresponding variances.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L29-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.loadings-Tuple{PPCA}" href="#MultivariateStats.loadings-Tuple{PPCA}"><code>MultivariateStats.loadings</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">loadings(M::PPCA)</code></pre><p>Returns the factor loadings matrix (of size <span>$(d, p)$</span>) of the model <code>M</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L47-L51">source</a></section></article><p>Given a probabilistic PCA model <span>$M$</span>, one can use it to transform observations into latent variables, as</p><pre><code class="language- hljs">\mathbf{z} = (\mathbf{W}^T \mathbf{W} + \sigma^2 \mathbf{I}) \mathbf{W}^T (\mathbf{x} - \boldsymbol{\mu})</code></pre><p>or use it to reconstruct (approximately) the observations from latent variables, as</p><pre><code class="language- hljs">\tilde{\mathbf{x}} = \mathbf{W} \mathbb{E}[\mathbf{z}] + \boldsymbol{\mu}</code></pre><p>Here, <span>$\mathbf{W}$</span> is the factor loadings or weight matrix.</p><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.predict-Union{Tuple{T}, Tuple{PPCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#StatsAPI.predict-Union{Tuple{T}, Tuple{PPCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>StatsAPI.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(M::PPCA, x)</code></pre><p>Transform observations <code>x</code> into latent variables. Here, <code>x</code> can be either a vector of length <code>d</code> or a matrix where each column is an observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L62-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{PPCA, AbstractVecOrMat{T}}} where T&lt;:Real" href="#MultivariateStats.reconstruct-Union{Tuple{T}, Tuple{PPCA, AbstractVecOrMat{T}}} where T&lt;:Real"><code>MultivariateStats.reconstruct</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reconstruct(M::PPCA, z)</code></pre><p>Approximately reconstruct observations from the latent variable given in <code>z</code>. Here, <code>z</code> can be either a vector of length <code>p</code> or a matrix where each column gives the latent variables for an observation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L74-L80">source</a></section></article><p>Auxiliary functions:</p><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.ppcaml" href="#MultivariateStats.ppcaml"><code>MultivariateStats.ppcaml</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">ppcaml(Z, mean; ...)</code></pre><p>Compute probabilistic PCA using on maximum likelihood formulation for a centralized sample matrix <code>Z</code>.</p><p><em>Parameters</em>:</p><ul><li><code>Z</code>: a centralized samples matrix</li><li><code>mean</code>: The mean vector of the <strong>original</strong> samples, which can be a vector of</li></ul><p>length <code>d</code>, or an empty vector indicating a zero mean.</p><p>Returns the resultant <a href="#MultivariateStats.PPCA"><code>PPCA</code></a> model.</p><p><strong>Note:</strong> This function accepts two keyword arguments: <code>maxoutdim</code> and <code>tol</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L97-L111">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.ppcaem" href="#MultivariateStats.ppcaem"><code>MultivariateStats.ppcaem</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">ppcaem(S, mean, n; ...)</code></pre><p>Compute probabilistic PCA based on expectation-maximization algorithm for a given sample covariance matrix <code>S</code>.</p><p><em>Parameters</em>:</p><ul><li><code>S</code>: The sample covariance matrix.</li><li><code>mean</code>: The mean vector of original samples, which can be a vector of length <code>d</code>,</li></ul><p>or an empty vector indicating a zero mean.</p><ul><li><code>n</code>: The number of observations.</li></ul><p>Returns the resultant <a href="#MultivariateStats.PPCA"><code>PPCA</code></a> model.</p><p><strong>Note:</strong> This function accepts three keyword arguments: <code>maxoutdim</code>, <code>tol</code>, and <code>maxiter</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L143-L157">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultivariateStats.bayespca" href="#MultivariateStats.bayespca"><code>MultivariateStats.bayespca</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">bayespca(S, mean, n; ...)</code></pre><p>Compute probabilistic PCA using a Bayesian algorithm for a given sample covariance matrix <code>S</code>.</p><p><em>Parameters</em>:</p><ul><li><code>S</code>: The sample covariance matrix.</li><li><code>mean</code>: The mean vector of original samples, which can be a vector of length <code>d</code>,</li></ul><p>or an empty vector indicating a zero mean.</p><ul><li><code>n</code>: The number of observations.</li></ul><p>Returns the resultant <a href="#MultivariateStats.PPCA"><code>PPCA</code></a> model.</p><p><strong>Notes:</strong></p><ul><li>This function accepts three keyword arguments: <code>maxoutdim</code>, <code>tol</code>, and <code>maxiter</code>.</li><li>Function uses the <code>maxoutdim</code> parameter as an upper boundary when it automatically</li></ul><p>determines the latent space dimensionality.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MultivariateStats.jl/blob/811f52211e3cc1c60c22ceaa6bb8ce40e0e25c7b/src/ppca.jl#L206-L223">source</a></section></article><hr/><h3 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h3><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Bishop, C. M. Pattern Recognition and Machine Learning, 2006.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../lda/">« Linear Discriminant Analysis</a><a class="docs-footer-nextpage" href="../ica/">Independent Component Analysis »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Wednesday 15 February 2023 14:32">Wednesday 15 February 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
